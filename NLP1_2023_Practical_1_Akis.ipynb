{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3rnwwoxm3pS"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antragoudaras/NLP_1/blob/main/NLP1_2023_Practical_1_Tony.ipynb\">\n",
        "<img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\" style=\"display: block; margin-left: auto; margin-right: auto; width: 200px;\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-aRiOgl4nHg"
      },
      "source": [
        "------\n",
        "**You cannot save any changes you make to this file, so please make sure to save it on your Google Colab drive or download it as a .ipynb file.**\n",
        "\n",
        "------\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIZrAUx57vsM"
      },
      "source": [
        "Practical 1: Sentiment Detection in Movie Reviews\n",
        "========================================\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4kXPMhyngZW"
      },
      "source": [
        "This practical concerns detecting sentiment in movie reviews. This is a typical NLP classification task.\n",
        "In [this file](https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json) (80MB) you will find 1000 positive and 1000 negative **movie reviews**.\n",
        "Each review is a **document** and consists of one or more sentences.\n",
        "\n",
        "To prepare yourself for this practical, you should\n",
        "have a look at a few of these texts to understand the difficulties of\n",
        "the task: how might one go about classifying the texts? You will write\n",
        "code that decides whether a movie review conveys positive or\n",
        "negative sentiment.\n",
        "\n",
        "Please make sure you have read the following paper:\n",
        "\n",
        ">   Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan\n",
        "(2002).\n",
        "[Thumbs up? Sentiment Classification using Machine Learning\n",
        "Techniques](https://dl.acm.org/citation.cfm?id=1118704). EMNLP.\n",
        "\n",
        "Bo Pang et al. introduced the movie review sentiment\n",
        "classification task, and the above paper was one of the first papers on\n",
        "the topic. The first version of your sentiment classifier will do\n",
        "something similar to Pang et al.'s system. If you have questions about it,\n",
        "you should resolve you doubts as soon as possible with your TA.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb7errgRASzZ"
      },
      "source": [
        "**Advice**\n",
        "\n",
        "Please read through the entire practical and familiarise\n",
        "yourself with all requirements before you start coding or otherwise\n",
        "solving the tasks. Writing clean and concise code can make the difference\n",
        "between solving the assignment in a matter of hours, and taking days to\n",
        "run all experiments.\n",
        "\n",
        "\n",
        "**Implementation**\n",
        "\n",
        "While we inserted code cells to indicate where you should implement your own code, please feel free to add/remove code blocks where you see fit (but make sure that the general structure of the assignment is preserved). Also, please keep in mind that it is always good practice to structure your code properly, e.g., by implementing separate classes and functions that can be reused.\n",
        "\n",
        "## Environment\n",
        "\n",
        "All code should be written in **Python 3**.\n",
        "This is the default in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaZnxptMJiD7",
        "outputId": "38401a7d-474c-4540-e2b5-b7f24b4ee71b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYZyIF7lJnGn"
      },
      "source": [
        "If you want to run code on your own computer, then download this notebook through `File -> Download .ipynb`.\n",
        "The easiest way to\n",
        "install Python is through downloading\n",
        "[Anaconda](https://www.anaconda.com/download).\n",
        "After installation, you can start the notebook by typing `jupyter notebook filename.ipynb`.\n",
        "You can also use an IDE\n",
        "such as [PyCharm](https://www.jetbrains.com/pycharm/download/) to make\n",
        "coding and debugging easier. It is good practice to create a [virtual\n",
        "environment](https://docs.python.org/3/tutorial/venv.html) for this\n",
        "project, so that any Python packages don’t interfere with other\n",
        "projects.\n",
        "\n",
        "\n",
        "**Learning Python 3**\n",
        "\n",
        "If you are new to Python 3, you may want to check out a few of these resources:\n",
        "- https://learnxinyminutes.com/docs/python3/\n",
        "- https://www.learnpython.org/\n",
        "- https://docs.python.org/3/tutorial/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hok-BFu9lGoK"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "import sys\n",
        "from subprocess import call\n",
        "from nltk import FreqDist\n",
        "from nltk.util import ngrams\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import sklearn as sk\n",
        "# from google.colab import drive\n",
        "import pickle\n",
        "import json\n",
        "from collections import Counter\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXWyGHwE-ieQ"
      },
      "source": [
        "## Loading the data\n",
        "\n",
        "**Download the sentiment lexicon and the movie reviews dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lm-rakqtlMOT",
        "outputId": "80054358-f759-4c3a-8279-ea354d5b5d80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-14 16:32:14--  https://gist.githubusercontent.com/bastings/d6f99dcb6c82231b94b013031356ba05/raw/f80a0281eba8621b122012c89c8b5e2200b39fd6/sent_lexicon\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 662577 (647K) [text/plain]\n",
            "Saving to: ‘sent_lexicon.2’\n",
            "\n",
            "\rsent_lexicon.2        0%[                    ]       0  --.-KB/s               \rsent_lexicon.2      100%[===================>] 647.05K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-11-14 16:32:14 (18.4 MB/s) - ‘sent_lexicon.2’ saved [662577/662577]\n",
            "\n",
            "--2023-11-14 16:32:14--  https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 83503869 (80M) [text/plain]\n",
            "Saving to: ‘reviews.json.2’\n",
            "\n",
            "reviews.json.2      100%[===================>]  79.63M   308MB/s    in 0.3s    \n",
            "\n",
            "2023-11-14 16:32:14 (308 MB/s) - ‘reviews.json.2’ saved [83503869/83503869]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download sentiment lexicon\n",
        "!wget https://gist.githubusercontent.com/bastings/d6f99dcb6c82231b94b013031356ba05/raw/f80a0281eba8621b122012c89c8b5e2200b39fd6/sent_lexicon\n",
        "# download review data\n",
        "!wget https://gist.githubusercontent.com/bastings/d47423301cca214e3930061a5a75e177/raw/5113687382919e22b1f09ce71a8fecd1687a5760/reviews.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkPwuHp5LSuQ"
      },
      "source": [
        "**Load the movie reviews.**\n",
        "\n",
        "Each word in a review comes with its part-of-speech tag. For documentation on POS-tags, see https://catalog.ldc.upenn.edu/docs/LDC99T42/tagguid1.pdf.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "careEKj-mRpl",
        "outputId": "058910a3-3ab9-4897-f9ea-b5b7ba321188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of reviews: 2000 \n",
            "\n",
            "0 NEG 29\n",
            "Two/CD teen/JJ couples/NNS go/VBP to/TO a/DT church/NN party/NN ,/, drink/NN and/CC then/RB drive/NN ./.\n",
            "1 NEG 11\n",
            "Damn/JJ that/IN Y2K/CD bug/NN ./.\n",
            "2 NEG 24\n",
            "It/PRP is/VBZ movies/NNS like/IN these/DT that/WDT make/VBP a/DT jaded/JJ movie/NN viewer/NN thankful/JJ for/IN the/DT invention/NN of/IN the/DT Timex/NNP IndiGlo/NNP watch/NN ./.\n",
            "3 NEG 19\n",
            "QUEST/NN FOR/IN CAMELOT/NNP ``/`` Quest/NNP for/IN Camelot/NNP ''/'' is/VBZ Warner/NNP Bros./NNP '/POS first/JJ feature-length/JJ ,/, fully-animated/JJ attempt/NN to/TO steal/VB clout/NN from/IN Disney/NNP 's/POS cartoon/NN empire/NN ,/, but/CC the/DT mouse/NN has/VBZ no/DT reason/NN to/TO be/VB worried/VBN ./.\n",
            "4 NEG 38\n",
            "Synopsis/NNPS :/: A/DT mentally/RB unstable/JJ man/NN undergoing/VBG psychotherapy/NN saves/VBZ a/DT boy/NN from/IN a/DT potentially/RB fatal/JJ accident/NN and/CC then/RB falls/VBZ in/IN love/NN with/IN the/DT boy/NN 's/POS mother/NN ,/, a/DT fledgling/NN restauranteur/NN ./.\n",
            "\n",
            "Number of word types: 47743\n",
            "Number of word tokens: 1512359\n",
            "\n",
            "Most common tokens:\n",
            "         , :    77842\n",
            "       the :    75948\n",
            "         . :    59027\n",
            "         a :    37583\n",
            "       and :    35235\n",
            "        of :    33864\n",
            "        to :    31601\n",
            "        is :    25972\n",
            "        in :    21563\n",
            "        's :    18043\n",
            "        it :    15904\n",
            "      that :    15820\n",
            "     -rrb- :    11768\n",
            "     -lrb- :    11670\n",
            "        as :    11312\n",
            "      with :    10739\n",
            "       for :     9816\n",
            "       his :     9542\n",
            "      this :     9497\n",
            "      film :     9404\n"
          ]
        }
      ],
      "source": [
        "# file structure:\n",
        "# [\n",
        "#  {\"cv\": integer, \"sentiment\": str, \"content\": list}\n",
        "#  {\"cv\": integer, \"sentiment\": str, \"content\": list}\n",
        "#   ..\n",
        "# ]\n",
        "# where `content` is a list of sentences,\n",
        "# with a sentence being a list of (token, pos_tag) pairs.\n",
        "\n",
        "\n",
        "with open(\"reviews.json\", mode=\"r\", encoding=\"utf-8\") as f:\n",
        "  reviews = json.load(f)\n",
        "\n",
        "print(\"Total number of reviews:\", len(reviews), '\\n')\n",
        "\n",
        "def print_sentence_with_pos(s):\n",
        "  print(\" \".join(\"%s/%s\" % (token, pos_tag) for token, pos_tag in s))\n",
        "\n",
        "for i, r in enumerate(reviews):\n",
        "  print(r[\"cv\"], r[\"sentiment\"], len(r[\"content\"]))  # cv, sentiment, num sents\n",
        "  print_sentence_with_pos(r[\"content\"][0])\n",
        "  if i == 4:\n",
        "    break\n",
        "\n",
        "c = Counter()\n",
        "for review in reviews:\n",
        "  for sentence in review[\"content\"]:\n",
        "    for token, pos_tag in sentence:\n",
        "      c[token.lower()] += 1\n",
        "\n",
        "print(\"\\nNumber of word types:\", len(c))\n",
        "print(\"Number of word tokens:\", sum(c.values()))\n",
        "\n",
        "print(\"\\nMost common tokens:\")\n",
        "for token, count in c.most_common(20):\n",
        "  print(\"%10s : %8d\" % (token, count))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6PWaEoh8B34"
      },
      "source": [
        "#(1) Lexicon-based approach (3.5pts)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsTSMb6ma4E8"
      },
      "source": [
        "A traditional approach to classify documents according to their sentiment is the lexicon-based approach. To implement this approach, you need a **sentiment lexicon**, i.e., a list of words annotated with a sentiment label (e.g., positive and negative, or a score from 0 to 5).\n",
        "\n",
        "In this practical, you will use the sentiment\n",
        "lexicon released by Wilson et al. (2005).\n",
        "\n",
        "> Theresa Wilson, Janyce Wiebe, and Paul Hoffmann\n",
        "(2005). [Recognizing Contextual Polarity in Phrase-Level Sentiment\n",
        "Analysis](http://www.aclweb.org/anthology/H/H05/H05-1044.pdf). HLT-EMNLP.\n",
        "\n",
        "Pay attention to all the information available in the sentiment lexicon. The field *word1* contains the lemma, *priorpolarity* contains the sentiment label (positive, negative, both, or neutral), *type* gives you the magnitude of the word's sentiment (strong or weak), and *pos1* gives you the part-of-speech tag of the lemma. Some lemmas can have multiple part-of-speech tags and thus multiple entries in the lexicon. The path of the lexicon file is `\"sent_lexicon\"`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogq0Eq2hQglh",
        "outputId": "e2e8029c-647b-419c-ba82-e3c93b13ad74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type=weaksubj len=1 word1=abandoned pos1=adj stemmed1=n priorpolarity=negative\n",
            "type=weaksubj len=1 word1=abandonment pos1=noun stemmed1=n priorpolarity=negative\n",
            "type=weaksubj len=1 word1=abandon pos1=verb stemmed1=y priorpolarity=negative\n",
            "type=strongsubj len=1 word1=abase pos1=verb stemmed1=y priorpolarity=negative\n",
            "type=strongsubj len=1 word1=abasement pos1=anypos stemmed1=y priorpolarity=negative\n"
          ]
        }
      ],
      "source": [
        "with open(\"sent_lexicon\", mode=\"r\", encoding=\"utf-8\") as f:\n",
        "  line_cnt = 0\n",
        "  for line in f:\n",
        "    print(line.strip())\n",
        "    line_cnt += 1\n",
        "    if line_cnt > 4:\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mml4nOtIUBhn"
      },
      "source": [
        "Lexica such as this can be used to solve\n",
        "the classification task without using Machine Learning. For example, one might look up every word $w_1 ... w_n$ in a document, and compute a **binary score**\n",
        "$S_{binary}$ by counting how many words have a positive or a\n",
        "negative label in the sentiment lexicon $SLex$.\n",
        "\n",
        "$$S_{binary}(w_1 w_2 ... w_n) = \\sum_{i = 1}^{n}\\text{sign}(SLex\\big[w_i\\big])$$\n",
        "\n",
        "where $\\text{sign}(SLex\\big[w_i\\big])$ refers to the polarity of $w_i$.\n",
        "\n",
        "**Threshold.** On average, there are more positive than negative words per review (~7.13 more positive than negative per review) to take this bias into account you should use a threshold of **8** (roughly the bias itself) to make it harder to classify as positive.\n",
        "\n",
        "$$\n",
        "\\text{classify}(S_{binary}(w_1 w_2 ... w_n)) = \\bigg\\{\\begin{array}{ll}\n",
        "        \\text{positive} & \\text{if } S_{binary}(w_1w_2...w_n) > threshold\\\\\n",
        "        \\text{negative} & \\text{otherwise}\n",
        "        \\end{array}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOFnMvbeeZrc"
      },
      "source": [
        "#### (Q1.1) Implement this approach and report its classification accuracy. (1 pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ED2aTEYutW1-"
      },
      "outputs": [],
      "source": [
        "def load_sent_lexicon(filename):\n",
        "  lexicon = {}\n",
        "  with open(filename, mode=\"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "      line_dict = {}\n",
        "      tokens = line.strip().split()\n",
        "      line_dict[tokens[-1].split('=')[0]] = tokens[-1].split('=')[1] #take 'pripolarity' token, pripolarity=['positive', 'negative' , 'neutral', 'both']\n",
        "      line_dict[tokens[0].split('=')[0]] = tokens[0].split('=')[1] #take 'type' token\n",
        "      lexicon[tokens[2].split('=')[1]] = line_dict\n",
        "  return lexicon\n",
        "\n",
        "def return_sign(token_lex_dict):\n",
        "    \"\"\"Returns the sign of the token polarity\"\"\"\n",
        "    if token_lex_dict[\"priorpolarity\"] == \"positive\":\n",
        "        return 1\n",
        "    elif token_lex_dict[\"priorpolarity\"] == \"negative\":\n",
        "        return -1\n",
        "    else: #neutral or both\n",
        "        return 0\n",
        "\n",
        "def tokenized_results(reviews, lex_dict, threshold=8):\n",
        "    \"\"\"Returns the predicted class label for each review, 1 if positive, 0 if negative\"\"\"\n",
        "    predictions = []\n",
        "    for review in reviews:\n",
        "        tokenized_results = []\n",
        "        for sentence in review[\"content\"]:\n",
        "            for token, _ in sentence:\n",
        "                if token.lower() in lex_dict:\n",
        "                    tokenized_results.append(return_sign(lex_dict[token.lower()]))\n",
        "        if np.sum(tokenized_results) > threshold:\n",
        "            predictions.append(1)\n",
        "        else:\n",
        "            predictions.append(0)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def return_true_labels(reviews):\n",
        "  return[1 if (review[\"sentiment\"] == 'POS') else  0 for review in reviews]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9eM4d_TXm3pa"
      },
      "outputs": [],
      "source": [
        "Lex_dict = load_sent_lexicon(\"sent_lexicon\")\n",
        "true_labels = return_true_labels(reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy528EUTphz5",
        "outputId": "ce3e50fd-9e58-42ea-8ff3-62df1205748a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.677\n"
          ]
        }
      ],
      "source": [
        "# token_results should be a list of binary indicators; for example [1, 0, 1, ...]\n",
        "# where 1 indicates a correct classification and 0 an incorrect classification.\n",
        "token_results = tokenized_results(reviews, Lex_dict, threshold=8)\n",
        "token_accuracy = sum([1 for i in range(len(token_results)) if token_results[i] == true_labels[i]]) / len(token_results)\n",
        "print(\"Accuracy: %0.3f\" % token_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twox0s_3eS0V"
      },
      "source": [
        "As the sentiment lexicon also has information about the **magnitude** of\n",
        "sentiment (e.g., *“excellent\"* has the same sentiment _polarity_ as *“good\"* but it has a higher magnitude), we can take a more fine-grained approach by adding up all\n",
        "sentiment scores, and deciding the polarity of the movie review using\n",
        "the sign of the weighted score $S_{weighted}$.\n",
        "\n",
        "$$S_{weighted}(w_1w_2...w_n) = \\sum_{i = 1}^{n}SLex\\big[w_i\\big]$$\n",
        "\n",
        "\n",
        "Make sure you define an appropriate threshold for this approach.\n",
        "\n",
        "#### (Q1.2) Now incorporate magnitude information and report the classification accuracy. Don't forget to use the threshold. (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qG3hUDnPtkhS"
      },
      "outputs": [],
      "source": [
        "def return_sign_magnitude(token_lex_dict, magnitude):\n",
        "    \"\"\"Returns the sign of the token polarity multiplied by the magnitude\"\"\"\n",
        "    if token_lex_dict[\"priorpolarity\"] == \"positive\":\n",
        "        if token_lex_dict['type'] == \"weaksubj\":\n",
        "            return 1\n",
        "        else:\n",
        "           return 1*magnitude\n",
        "    elif token_lex_dict[\"priorpolarity\"] == \"negative\":\n",
        "        if token_lex_dict['type'] == \"weaksubj\":\n",
        "            return -1\n",
        "        else:\n",
        "           return -1*magnitude\n",
        "    else: #neutral or both\n",
        "        return 0\n",
        "\n",
        "def tokenized_results_magnitude(reviews, lex_dict, threshold=8, magnitude=1.5):\n",
        "    \"\"\"Returns the predicted class label for each review, 1 if positive, 0 if negative\"\"\"\n",
        "    predictions = []\n",
        "    for review in reviews:\n",
        "        tokenized_results = []\n",
        "        for sentence in review[\"content\"]:\n",
        "            for token, _ in sentence:\n",
        "                if token.lower() in lex_dict:\n",
        "                    tokenized_results.append(return_sign_magnitude(lex_dict[token.lower()], magnitude))\n",
        "\n",
        "        if sum(tokenized_results) > threshold:\n",
        "            predictions.append(1)\n",
        "        else:\n",
        "            predictions.append(0)\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vVk7CvDpyka",
        "outputId": "f9e70f9b-d328-4a97-e208-eca934b409aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.687\n"
          ]
        }
      ],
      "source": [
        "token_results = tokenized_results_magnitude(reviews, Lex_dict, threshold=16, magnitude=2)\n",
        "magnitude_accuracy = sum([1 for i in range(len(token_results)) if token_results[i] == true_labels[i]]) / len(token_results)\n",
        "print(\"Accuracy: %0.3f\" % magnitude_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9SHoGPfsAHV"
      },
      "source": [
        "#### (Q.1.3) Make a barplot of the two results (0.5pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8LgBcYcXsEk3",
        "outputId": "32de0519-bda7-4bc6-b371-ffb8c1b9ad2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x900 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotting the accuracies in a bar plot\n",
        "fig = plt.figure(figsize=(5, 9))\n",
        "accuracies = [100*token_accuracy, 100*magnitude_accuracy]\n",
        "labels = ['Accuracy \\n no Magnitude', 'Accuracy \\n w\\ Magnitude']\n",
        "colors = ['red', 'green'] # add colors for each element in accuracies\n",
        "plt.bar(labels, accuracies, color=colors) # use the colors parameter to set the colors\n",
        "plt.title('Accuracy Comparison')\n",
        "plt.xlabel('Classification Method')\n",
        "plt.ylabel('Accuracy %')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNhS8OCVxMHd"
      },
      "source": [
        "#### (Q1.4) A better threshold (1pt)\n",
        "Above we have defined a threshold to account for an inherent bias in the dataset: there are more positive than negative words per review.\n",
        "However, that threshold does not take into account *document length*. Explain why this is a problem and implement an alternative way to compute the threshold."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xo7gk1I-omLI"
      },
      "source": [
        "**Answer Q1.4**:\n",
        "\n",
        "The problem is that since we have used a fixed threshold (that captures the bias in the dataset), reviews of larger or smaller sizes than the average could be classified incorrectly. For example, the threshold must be adequately downscaled for a positive review with fewer words than the average to be classified correctly. Similarly, we need to adjust the threshold for reviews with more words than the average.\n",
        "\n",
        "In order to resolve this problem, we have created two methods, both taking into account the document length (size of the review).\n",
        "Instead of considering the dataset's bias, the first approach compares the average ratio of the weighted binary score with respect to words per review of all reviews to the ratio of the weighted binary score to words per review for the review in test time.\n",
        "\n",
        "The second approach calculates a normalized threshold per review in test time by multiplying the original threshold with the ratio of words in the tested review to the average words per review (calculated by taking into account all reviews): $\\newline$\n",
        "$$\\frac{words\\_in\\_a\\_review\\_under\\_test}{average\\_words\\_per\\_review}$$\n",
        "\n",
        "Then, the weighted binary score of each review is compared to the following normalized threshold: $$orig\\_thes. \\times \\frac{words\\_in\\_a\\_review\\_under\\_test}{average\\_words\\_per\\_review}$$ and a classification decision is made."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YQua9UnGm3pb"
      },
      "outputs": [],
      "source": [
        "def calc_avg_score(reviews, lex_dict, magnitude):\n",
        "    \"\"\"Returns the dynamic threshold for a given set of reviews - Method 1\"\"\"\n",
        "    scores = []\n",
        "    for review in reviews:\n",
        "        tokenized_results = []\n",
        "        words_per_review = 0\n",
        "        for sentence in review[\"content\"]:\n",
        "            for token, _ in sentence:\n",
        "                words_per_review += 1\n",
        "                if token.lower() in lex_dict:\n",
        "                    tokenized_results.append(return_sign_magnitude(lex_dict[token.lower()], magnitude))\n",
        "        scores.append(sum(tokenized_results)/words_per_review) # calculate the average score for each review\n",
        "    return np.mean(scores) # return the average score for all reviews\n",
        "\n",
        "\n",
        "def tokenized_dynamic_threshold(reviews, lex_dict, magnitude=1.5):\n",
        "    \"\"\"Returns the predicted class label for each review, 1 if positive, 0 if negative with dynamic threshold - Method 1 without the use of original threshold\"\"\"\n",
        "    avg_score = calc_avg_score(reviews, lex_dict, magnitude)\n",
        "    predictions = []\n",
        "    for review in reviews:\n",
        "        tokenized_results = []\n",
        "        words_per_review = 0\n",
        "        for sentence in review[\"content\"]:\n",
        "            for token, _ in sentence:\n",
        "                words_per_review += 1\n",
        "                if token.lower() in lex_dict:\n",
        "                    tokenized_results.append(return_sign_magnitude(lex_dict[token.lower()], magnitude))\n",
        "\n",
        "        if sum(tokenized_results) / words_per_review > avg_score:\n",
        "            predictions.append(1)\n",
        "        else:\n",
        "            predictions.append(0)\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8obXf4Ojm3pb",
        "outputId": "b8de48f6-8bcb-434c-b235-912170b3d228",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 69.15%\n"
          ]
        }
      ],
      "source": [
        "adjusted_token_results = tokenized_dynamic_threshold(reviews, Lex_dict, magnitude=2)\n",
        "dynamic_accuracy = sum([1 for i in range(len(adjusted_token_results)) if adjusted_token_results[i] == true_labels[i]]) / len(adjusted_token_results)\n",
        "print(f\"Accuracy: {100*dynamic_accuracy}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mVg7gD9sm3pb"
      },
      "outputs": [],
      "source": [
        "def calc_avg_words_per_review(reviews):\n",
        "    \"\"\"Returns the average number of words per review\"\"\"\n",
        "    total_words = sum(len(sentence) for review in reviews for sentence in review[\"content\"])\n",
        "    avg_words_per_review = int(total_words / len(reviews))\n",
        "    return avg_words_per_review\n",
        "\n",
        "def tokenized_dynamic_threshold_w_org_thres(reviews, lex_dict, original_threshold=8, magnitude=1.5):\n",
        "    \"\"\"Returns the predicted class label for each review, 1 if positive, 0 if negative with dynamic threshold - Method 2 with the use of original threshold\"\"\"\n",
        "    avg_words_per_review = calc_avg_words_per_review(reviews)\n",
        "    predictions = []\n",
        "    for review in reviews:\n",
        "        tokenized_results = []\n",
        "        words_per_review = 0\n",
        "        for sentence in review[\"content\"]:\n",
        "            for token, _ in sentence:\n",
        "                words_per_review += 1\n",
        "                if token.lower() in lex_dict:\n",
        "                    tokenized_results.append(return_sign_magnitude(lex_dict[token.lower()], magnitude))\n",
        "\n",
        "        normalized_threshold = original_threshold * (words_per_review / avg_words_per_review)\n",
        "        if sum(tokenized_results) > normalized_threshold:\n",
        "            predictions.append(1)\n",
        "        else:\n",
        "            predictions.append(0)\n",
        "\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Dwt0B8h8aKjr",
        "outputId": "e58f3db5-8a23-4631-895b-9b0566393cfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 69.19999999999999%\n"
          ]
        }
      ],
      "source": [
        "dynamic_token_results = tokenized_dynamic_threshold_w_org_thres(reviews, Lex_dict, original_threshold=16, magnitude=2)\n",
        "dynamic_accuracy = sum([1 for i in range(len(dynamic_token_results)) if dynamic_token_results[i] == true_labels[i]]) / len(dynamic_token_results)\n",
        "print(f\"Accuracy: {100*dynamic_accuracy}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LibV4nR89BXb"
      },
      "source": [
        "# (2) Naive Bayes (9.5pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnF9adQnuwia"
      },
      "source": [
        "\n",
        "Your second task is to program a simple Machine Learning approach that operates\n",
        "on a simple Bag-of-Words (BoW) representation of the text data, as\n",
        "described by Pang et al. (2002). In this approach, the only features we\n",
        "will consider are the words in the text themselves, without bringing in\n",
        "external sources of information. The BoW model is a popular way of\n",
        "representing texts as vectors, making it\n",
        "easy to apply classical Machine Learning algorithms on NLP tasks.\n",
        "However, the BoW representation is also very crude, since it discards\n",
        "all information related to word order and grammatical structure in the\n",
        "original text—as the name suggests.\n",
        "\n",
        "## Writing your own classifier (4pts)\n",
        "\n",
        "Write your own code to implement the Naive Bayes (NB) classifier. As\n",
        "a reminder, the Naive Bayes classifier works according to the following\n",
        "equation:\n",
        "$$\\hat{c} = \\operatorname*{arg\\,max}_{c \\in C} P(c|\\bar{f}) = \\operatorname*{arg\\,max}_{c \\in C} P(c)\\prod^n_{i=1} P(f_i|c)$$\n",
        "where $C = \\{ \\text{POS}, \\text{NEG} \\}$ is the set of possible classes,\n",
        "$\\hat{c} \\in C$ is the most probable class, and $\\bar{f}$ is the feature\n",
        "vector. Remember that we use the log of these probabilities when making\n",
        "a prediction:\n",
        "$$\\hat{c} = \\operatorname*{arg\\,max}_{c \\in C} \\Big\\{\\log P(c) + \\sum^n_{i=1} \\log P(f_i|c)\\Big\\}$$\n",
        "\n",
        "You can find more details about Naive Bayes in [Jurafsky &\n",
        "Martin](https://web.stanford.edu/~jurafsky/slp3/). You can also look at\n",
        "this helpful\n",
        "[pseudo-code](https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html).\n",
        "\n",
        "*Note: this section and the next aim to put you in a position to replicate\n",
        "    Pang et al.'s Naive Bayes results. However, your numerical results\n",
        "    will differ from theirs, as they used different data.*\n",
        "\n",
        "**You must write the Naive Bayes training and prediction code from\n",
        "scratch.** You will not be given credit for using off-the-shelf Machine\n",
        "Learning libraries.\n",
        "\n",
        "The data contains the text of the reviews, where each document consists\n",
        "of the sentences in the review, the sentiment of the review and an index\n",
        "(cv) that you will later use for cross-validation. The\n",
        "text has already been tokenised and POS-tagged for you. Your algorithm\n",
        "should read in the text, **lowercase it**, store the words and their\n",
        "frequencies in an appropriate data structure that allows for easy\n",
        "computation of the probabilities used in the Naive Bayes algorithm, and\n",
        "then make predictions for new instances.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEpyQSBSkb33"
      },
      "source": [
        "#### (Q2.1) Unseen words (1pt)\n",
        "The presence of words in the test dataset that\n",
        "have not been seen during training can cause probabilities in the Naive Bayes classifier to equal $0$.\n",
        "These can be words which are unseen in both positive and negative training reviews (case 1), but also words which are seen in reviews _of only one sentiment class_ in the training dataset (case 2). In both cases, **you should skip these words for both classes at test time**.  What would be the problem instead with skipping words only for one class in case 2?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BanFiYYnoxDW"
      },
      "source": [
        "**Answer Q2.1**: TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "a_O0kSXSm3pc"
      },
      "outputs": [],
      "source": [
        "def get_train_test_set(reviews, train_size_per_sentiment=900):\n",
        "    \"\"\"Returns the train and test set of the reviews with the specified train and test size\"\"\"\n",
        "    train_set = [review for review in reviews if review[\"cv\"] < train_size_per_sentiment]\n",
        "    test_set = [review for review in reviews if review[\"cv\"] >=train_size_per_sentiment]\n",
        "    return train_set, test_set\n",
        "\n",
        "def get_unique_per_class_tokens(reviews_train_set):\n",
        "    \"\"\"Returns a set of unique tokens that make of vocab, for negative and positive reviews separately\"\"\"\n",
        "    negative_vocab = set(token.lower() for review in reviews_train_set if review['sentiment'] == 'NEG' for sentence in review[\"content\"] for token, _ in sentence)\n",
        "    positive_vocab = set(token.lower() for review in reviews_train_set if review['sentiment'] == 'POS' for sentence in review[\"content\"] for token, _ in sentence)\n",
        "    return negative_vocab, positive_vocab\n",
        "\n",
        "\n",
        "def ignore_unseen_words(reviews_train_set, reviews_test_set):\n",
        "    \"\"\"Returns the modified test set where unseen words in training that have been removed\"\"\"\n",
        "    unique_negative_tokens, unique_positive_tokens = get_unique_per_class_tokens(reviews_train_set)\n",
        "    processed_test_set = copy.deepcopy(reviews_test_set)\n",
        "    for review in processed_test_set:\n",
        "        for sentence in review[\"content\"]:\n",
        "            i = 0\n",
        "            while i < len(sentence):\n",
        "                token, _ = sentence[i]\n",
        "                if (token.lower() in unique_negative_tokens) and (token.lower() in unique_positive_tokens): #seen in both classes\n",
        "                    i += 1\n",
        "                else: #remove the token from the sentence, case 1 not seen in both classes, case 2 not seen in either positive or negative class\n",
        "                    sentence.pop(i)\n",
        "    return processed_test_set\n",
        "\n",
        "def ignore_unseen_words_second(reviews_train_set, reviews_test_set):\n",
        "    \"\"\"Returns the modified test set where unseen words in training that have been removed\"\"\"\n",
        "    unique_negative_tokens, unique_positive_tokens = get_unique_per_class_tokens(reviews_train_set)\n",
        "    processed_test_set = copy.deepcopy(reviews_test_set)\n",
        "    processed_train_set = copy.deepcopy(reviews_train_set)\n",
        "    for review in processed_test_set:\n",
        "        for sentence in review[\"content\"]:\n",
        "            i = 0\n",
        "            while i < len(sentence):\n",
        "                token, _ = sentence[i]\n",
        "                if (token.lower() not in unique_negative_tokens) and (token.lower() not in unique_positive_tokens): #seen in both classes\n",
        "                    sentence.pop(i)\n",
        "                else: #remove the token from the sentence, case 1 not seen in both classes, case 2 not seen in either positive or negative class\n",
        "                    i += 1\n",
        "    for review in processed_train_set:\n",
        "        if review['sentiment'] == 'NEG':\n",
        "            for sentence in review[\"content\"]:\n",
        "                i = 0\n",
        "                while i < len(sentence):\n",
        "                    token, _ = sentence[i]\n",
        "                    if (token.lower() not in unique_positive_tokens):\n",
        "                        sentence.pop(i)\n",
        "                    else:\n",
        "                        i += 1\n",
        "    for review in processed_train_set:\n",
        "        if review['sentiment'] == 'POS':\n",
        "            for sentence in review[\"content\"]:\n",
        "                i = 0\n",
        "                while i < len(sentence):\n",
        "                    token, _ = sentence[i]\n",
        "                    if (token.lower() not in unique_negative_tokens):\n",
        "                        sentence.pop(i)\n",
        "                    else:\n",
        "                        i += 1\n",
        "\n",
        "    return processed_train_set, processed_test_set\n",
        "\n",
        "def vocab_size(input_set):\n",
        "    \"\"\"Returns the size of the vocabulary of the input set\"\"\"\n",
        "    return len(set(token.lower() for review in input_set for sentence in review[\"content\"] for token, _ in sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tpnIoJtmm3pc",
        "outputId": "f6b6370f-b6b0-4f4e-a700-329e86a68843",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size of test_set before removing unseen words: 14812\n",
            "Vocab size of test_set after removing unseen words: 12417\n"
          ]
        }
      ],
      "source": [
        "reviews_train_set, reviews_test_set = get_train_test_set(reviews, train_size_per_sentiment=900)\n",
        "processed_train_set, processed_test_set = ignore_unseen_words_second(reviews_train_set, reviews_test_set)\n",
        "print('Vocab size of test_set before removing unseen words:', vocab_size(reviews_test_set))\n",
        "print('Vocab size of test_set after removing unseen words:', vocab_size(processed_test_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsZRhaI3WvzC"
      },
      "source": [
        "#### (Q2.2) Train your classifier on (positive and negative) reviews with cv-value 000-899, and test it on the remaining (positive and negative) reviews cv900–cv999.  Report results using classification accuracy as your evaluation metric. Your  features are the word vocabulary. The value of a feature is the count of that feature (word) in the document. (2pts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "G7zaJYGFvIJ3"
      },
      "outputs": [],
      "source": [
        "def get_vocab(input_set):\n",
        "    \"\"\"Returns a set of unique tokens from all the sentences of the input set\"\"\"\n",
        "    return set(token.lower() for review in input_set for sentence in review[\"content\"] for token, _ in sentence if len(token.split()) == 1)\n",
        "def get_full_vocab(input_set):\n",
        "    \"\"\"Returns a set of unique tokens from all the sentences of the input set\"\"\"\n",
        "    return set(token.lower() for review in input_set for sentence in review[\"content\"] for token, _ in sentence)\n",
        "def count_total_docs(input_set):\n",
        "    \"\"\"Returns the total number of documents/reviews in the input set\"\"\"\n",
        "    return sum(1 for review in input_set)\n",
        "\n",
        "def count_docs_in_class(input_set, class_label):\n",
        "    \"\"\"Returns the total number of documents/sentences in the input set belonging to a class\"\"\"\n",
        "    return sum(1 for review in input_set if review[\"sentiment\"] == class_label)\n",
        "\n",
        "def concat_text_of_docs_in_class(input_set, class_label):\n",
        "    \"\"\"Returns a list of words/tokens of the concatenated sentences of all reviews for a specific class_label\"\"\"\n",
        "    return [token.lower() for review in input_set if review[\"sentiment\"] == class_label for sentence in review[\"content\"] for token, _ in sentence]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "26-7uT3ym3pf",
        "outputId": "275c8390-e4f5-4d5f-d684-3583814184fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of Reviews/Docs in train set(both in positive and negative class): 1800\n",
            "Num. of reviews/#Docs in positive class: 900\n",
            "Num. of reviews/#Docs in negative class: 900\n"
          ]
        }
      ],
      "source": [
        "print(\"Total number of Reviews/Docs in train set(both in positive and negative class):\", count_total_docs(reviews_train_set))\n",
        "print('Num. of reviews/#Docs in positive class:', count_docs_in_class(reviews_train_set, class_label=\"POS\"))\n",
        "print('Num. of reviews/#Docs in negative class:', count_docs_in_class(reviews_train_set, class_label=\"NEG\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "PGSLCuUhm3pg"
      },
      "outputs": [],
      "source": [
        "def train_NB(reviews_train_set, k_smoothing, class_labels = [\"POS\", \"NEG\"]):\n",
        "    \"\"\"Trains NB without smoothing, Returns the vocabulary, prior probability of each class and conditional probability of each word given a class\"\"\"\n",
        "    vocabulary = get_vocab(reviews_train_set) #extract vocabulary\n",
        "    total_docs = count_total_docs(reviews_train_set) #count total number of documents\n",
        "    class_prior_prob = {}\n",
        "    class_cond_prob = {}\n",
        "    actual_vocab = {class_label: set() for class_label in class_labels}\n",
        "    for class_label in class_labels: #iterate through each class\n",
        "        docs_in_class = count_docs_in_class(reviews_train_set, class_label)\n",
        "        class_prior_prob[class_label] =  docs_in_class / total_docs #calculate prior probability of a class\n",
        "        text_class = concat_text_of_docs_in_class(reviews_train_set, class_label) #\n",
        "        word_freq = Counter(text_class) #count the frequency of each word in the text of a class\n",
        "        class_cond_prob[class_label] = {}\n",
        "        sum_of_words_freq = sum(word_freq.values()) #sum of frequency of all words in the vocabulary\n",
        "        if k_smoothing is not None:\n",
        "            for token, freq in word_freq.items():\n",
        "                actual_vocab[class_label].add(token)\n",
        "                if len(token.split()) > 1:\n",
        "                    sub_t = ' '.join(token.split()[:-1])\n",
        "                    sub_freq = word_freq[sub_t]\n",
        "                    class_cond_prob[class_label][token] = (freq + k_smoothing) / (sub_freq + k_smoothing*len(vocabulary))\n",
        "                else:\n",
        "                    class_cond_prob[class_label][token] = (freq + k_smoothing) / (sum_of_words_freq + k_smoothing*len(vocabulary))\n",
        "        else:\n",
        "            for token, freq in word_freq.items(): #iterate through each word in the vocabulary\n",
        "                if freq != 0: #if token is present in the text of a class, only then add it to our probab calculations\n",
        "                    actual_vocab[class_label].add(token)\n",
        "                    class_cond_prob[class_label][token] = freq / sum_of_words_freq #calculate conditional probability of a word given a class\n",
        "    return actual_vocab, class_prior_prob, class_cond_prob\n",
        "\n",
        "\n",
        "def train_NB_second(reviews_train_set, k_smoothing, class_labels = [\"POS\", \"NEG\"]):\n",
        "    \"\"\"Trains NB without smoothing, Returns the vocabulary, prior probability of each class and conditional probability of each word given a class\"\"\"\n",
        "    vocabulary = get_vocab(reviews_train_set) #extract vocabulary\n",
        "    original_vocab = get_full_vocab(reviews_train_set)\n",
        "    total_docs = count_total_docs(reviews_train_set) #count total number of documents\n",
        "    class_prior_prob = {}\n",
        "    class_cond_prob = {}\n",
        "    total_freq_per_class = {}\n",
        "    actual_vocab = {class_label: set() for class_label in class_labels}\n",
        "    for class_label in class_labels: #iterate through each class\n",
        "        docs_in_class = count_docs_in_class(reviews_train_set, class_label)\n",
        "        class_prior_prob[class_label] =  docs_in_class / total_docs #calculate prior probability of a class\n",
        "        text_class = concat_text_of_docs_in_class(reviews_train_set, class_label) #\n",
        "        word_freq = Counter(text_class) #count the frequency of each word in the text of a class\n",
        "        class_cond_prob[class_label] = {}\n",
        "        sum_of_words_freq = sum(word_freq.values()) #sum of frequency of all words in the vocabulary\n",
        "        total_freq_per_class[class_label] = sum_of_words_freq\n",
        "\n",
        "        for token, freq in word_freq.items():\n",
        "\n",
        "            if k_smoothing is None:\n",
        "                if freq != 0: #if token is present in the text of a class, only then add it to our probab calculations\n",
        "                    actual_vocab[class_label].add(token)\n",
        "                    class_cond_prob[class_label][token] = freq / sum_of_words_freq #calculate conditional probability of a word given a class\n",
        "            else:\n",
        "                actual_vocab[class_label].add(token)\n",
        "                if len(token.split()) > 1:\n",
        "                    sub_t = ' '.join(token.split()[:-1])\n",
        "                    sub_freq = word_freq[sub_t]\n",
        "                    class_cond_prob[class_label][token] = (freq + k_smoothing) / (sub_freq + k_smoothing*len(vocabulary))\n",
        "                else:\n",
        "                    class_cond_prob[class_label][token] = (freq + k_smoothing) / (sum_of_words_freq + k_smoothing*len(vocabulary))\n",
        "    return actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, len(original_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hzu1NHMJm3pg"
      },
      "outputs": [],
      "source": [
        "def extract_unique_tokens_from_review(review):\n",
        "    \"\"\"Returns a set of unique tokens from all the sentences of a single review\"\"\"\n",
        "    return set(token.lower() for sentence in review[\"content\"] for token, _ in sentence)\n",
        "def extract_tokens_from_review(review):\n",
        "    \"\"\"Returns a set of unique tokens from all the sentences of a single review\"\"\"\n",
        "    return [token.lower() for sentence in review[\"content\"] for token, _ in sentence]\n",
        "\n",
        "def NB_per_review(review, actual_vocab, class_prior_prob, class_cond_prob, unique_tokens, k_smoothing, class_labels = [\"POS\", \"NEG\"]):\n",
        "    \"\"\"Returns the predicted class label for a single review 1 if positive, 0 if negative\"\"\"\n",
        "    score_per_class_label = {}\n",
        "    if unique_tokens == True:\n",
        "        W = extract_unique_tokens_from_review(review)\n",
        "    else:\n",
        "        W = extract_tokens_from_review(review)\n",
        "\n",
        "    for class_label in class_labels:\n",
        "        score_per_class_label[class_label] = math.log(class_prior_prob[class_label])\n",
        "        if k_smoothing is None:\n",
        "            for t in W:\n",
        "                if t in actual_vocab[class_label]: #only needed if we did not use smoothing\n",
        "                    score_per_class_label[class_label] += math.log(class_cond_prob[class_label][t])\n",
        "        else:\n",
        "            for t in W:\n",
        "                    score_per_class_label[class_label] += math.log(class_cond_prob[class_label][t])\n",
        "    prediction = max(score_per_class_label, key=score_per_class_label.get) #return the class 'str' label with the highest score\n",
        "    return 1 if prediction == \"POS\" else 0\n",
        "\n",
        "def NB_per_review_second(review, actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len, unique_tokens, k_smoothing, remove_words=True, class_labels = [\"POS\", \"NEG\"]):\n",
        "    \"\"\"Returns the predicted class label for a single review 1 if positive, 0 if negative\"\"\"\n",
        "    score_per_class_label = {}\n",
        "    if unique_tokens == True:\n",
        "        W = extract_unique_tokens_from_review(review)\n",
        "    else:\n",
        "        W = extract_tokens_from_review(review)\n",
        "\n",
        "    for class_label in class_labels:\n",
        "        score_per_class_label[class_label] = math.log(class_prior_prob[class_label])\n",
        "\n",
        "        for t in W:\n",
        "            if k_smoothing is not None:\n",
        "                if t in actual_vocab[class_label]:\n",
        "                    score_per_class_label[class_label] += math.log(class_cond_prob[class_label][t])\n",
        "                else:\n",
        "                    if remove_words == False or len(t.split()) > 1:\n",
        "                        score_per_class_label[class_label] += math.log(k_smoothing / (total_freq_per_class[class_label] + (k_smoothing * vocab_len)))\n",
        "            else:\n",
        "                if t in actual_vocab[class_label]:\n",
        "                    score_per_class_label[class_label] += math.log(class_cond_prob[class_label][t])\n",
        "\n",
        "    prediction = max(score_per_class_label, key=score_per_class_label.get) #return the class 'str' label with the highest score\n",
        "    return 1 if prediction == \"POS\" else 0\n",
        "\n",
        "def test_NB(test_set, actual_vocab, class_prior_prob, class_cond_prob, unique_tokens, k_smoothing):\n",
        "    \"\"\"Returns a list of predicted class labels for the test set, 1 if the review was positive, 0 if negative\"\"\"\n",
        "    predictions = []\n",
        "    for review in test_set:\n",
        "        predictions.append(NB_per_review(review, actual_vocab, class_prior_prob, class_cond_prob, unique_tokens, k_smoothing=k_smoothing))\n",
        "    return predictions\n",
        "\n",
        "def test_NB_second(test_set, actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len, unique_tokens, k_smoothing, remove_words=True):\n",
        "    \"\"\"Returns a list of predicted class labels for the test set, 1 if the review was positive, 0 if negative\"\"\"\n",
        "    predictions = []\n",
        "    for review in test_set:\n",
        "        predictions.append(NB_per_review_second(review, actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len, unique_tokens, k_smoothing=k_smoothing, remove_words=remove_words))\n",
        "    return predictions\n",
        "\n",
        "def calculate_accuracy(predictions, true_labels):\n",
        "    return sum([1 for i in range(len(predictions)) if predictions[i] == true_labels[i]]) / len(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "S4ANzka2m3pg",
        "outputId": "c450720e-06a2-452a-fe73-c179f4537a42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training NB with smoothing on balanced dataset ...... without removing unseen words\n",
            "Testing NB with smoothing ...... without removing unseen words\n",
            "NB classification accuracy: 46.0% with unique tokens\n",
            "NB classification accuracy: 49.5% without unique tokens\n"
          ]
        }
      ],
      "source": [
        "print(\"Training NB with smoothing on balanced dataset ...... without removing unseen words\")\n",
        "actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len = train_NB_second(reviews_train_set, k_smoothing=None)\n",
        "\n",
        "print(\"Testing NB with smoothing ...... without removing unseen words\")\n",
        "test_predictions = test_NB_second(reviews_test_set, actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len, unique_tokens=True, k_smoothing=None, remove_words=False)\n",
        "test_true_labels = return_true_labels(reviews_test_set)\n",
        "accuracy = calculate_accuracy(test_predictions, test_true_labels)\n",
        "print(f\"NB classification accuracy: {100*accuracy}% with unique tokens\")\n",
        "\n",
        "test_predictions = test_NB_second(reviews_test_set, actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len, unique_tokens=False, k_smoothing=None, remove_words=False)\n",
        "accuracy = calculate_accuracy(test_predictions, test_true_labels)\n",
        "print(f\"NB classification accuracy: {100*accuracy}% without unique tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RM1GO60km3pg",
        "outputId": "72e0ed65-91c5-4652-8c64-5bf9edeba3c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training NB without smoothing on balanced dataset ...... after removing unseen words\n",
            "Testing NB without smoothing ...... after removing unseen words\n",
            "NB classification Accuracy: 87.5% without smoothing using unique tokens\n",
            "NB classification Accuracy: 83.5% without smoothing, without using unique tokens\n"
          ]
        }
      ],
      "source": [
        "print(\"Training NB without smoothing on balanced dataset ...... after removing unseen words\")\n",
        "actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len = train_NB_second(processed_train_set, k_smoothing=None)\n",
        "\n",
        "print(\"Testing NB without smoothing ...... after removing unseen words\")\n",
        "test_predictions = test_NB_second(processed_test_set, actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len, unique_tokens=True, k_smoothing=None)\n",
        "test_true_labels = return_true_labels(processed_test_set)\n",
        "accuracy = calculate_accuracy(test_predictions, test_true_labels)\n",
        "print(f\"NB classification Accuracy: {100*accuracy}% without smoothing using unique tokens\")\n",
        "\n",
        "test_predictions = test_NB_second(processed_test_set, actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len, unique_tokens=False, k_smoothing=None)\n",
        "accuracy = calculate_accuracy(test_predictions, test_true_labels)\n",
        "print(f\"NB classification Accuracy: {100*accuracy}% without smoothing, without using unique tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0INK-PBoM6CB"
      },
      "source": [
        "#### (Q2.3) Would you consider accuracy to also be a good way to evaluate your classifier in a situation where 90% of your data instances are of positive movie reviews? (1pt)\n",
        "\n",
        "Simulate this scenario by keeping the positive reviews\n",
        "data unchanged, but only using negative reviews cv000–cv089 for\n",
        "training, and cv900–cv909 for testing. Calculate the classification\n",
        "accuracy, and explain what changed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFbcsYlipBAw"
      },
      "source": [
        "**Answer Q2.3**:\n",
        "\n",
        "Using the unbalanced dataset ($90\\%$ of the reviews in the training set are positive, $10\\%$ are negative), our classifier almost overfits the majority class (positive) during test time. The fact that the classification accuracy is high ($\\approx 90\\%$) does not translate to the classifier capturing the actual pattern in the test set. That is because there are only 100 negative reviews and 100 positive ones in our test set. In most test cases, our classifier predicts the positive class (a positive review). Because of the unbalanced dataset, it acquires a high accuracy. In such cases, we are usually interested in other classification metrics, considering TP, FP, TN, FN, when calculating the accuracy metric. In this case, Specificity ($\\frac{TN}{TN+FP}$) could be an excellent metric to capture the performance of our classifier for capturing the accuracy in the negative test cases in this unbalanced scenario. Based on the following source: (https://miro.medium.com/v2/0*-oGC3SE8sPCPdmxs.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GWDkt5ZrrFGp"
      },
      "outputs": [],
      "source": [
        "def get_unbalanced_set(reviews, negative_sentiment_train_size=90, positive_sentiment_train_size=900):\n",
        "    \"\"\"Returns the train and test set of the reviews with the specified train and test size\"\"\"\n",
        "    train_set, test_set = [], []\n",
        "    for review in reviews: #iterate through the first 90 negative reviews\n",
        "        if review[\"sentiment\"] == 'NEG':\n",
        "            if review[\"cv\"] < negative_sentiment_train_size:\n",
        "                train_set.append(review)\n",
        "            elif review[\"cv\"] >= (10*negative_sentiment_train_size) and review[\"cv\"] < (10*negative_sentiment_train_size + 10):\n",
        "                test_set.append(review)\n",
        "\n",
        "    for review in reviews: #iterate through the first 1000 positive reviews\n",
        "        if review[\"sentiment\"] == 'POS':\n",
        "            if review[\"cv\"] < positive_sentiment_train_size:\n",
        "                train_set.append(review)\n",
        "            else:\n",
        "                test_set.append(review)\n",
        "    return train_set, test_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8XijlHKvm3ph",
        "outputId": "49e7fd8d-89fa-482f-9d63-7cd28f796771",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size of test_set before removing unseen words: 10639\n",
            "Vocab size of test_set after removing unseen words: 8797\n",
            "Training NB on the unbalanced dataset without smoothing ......\n",
            "Testing NB on the unbalanced dataset without smoothing ......\n",
            "NB classification Accuracy: 91.81818181818183% on the unbalanced dataset with unique tokens\n",
            "NB classification Accuracy: 89.0909090909091% on the unbalanced dataset without unique tokens\n"
          ]
        }
      ],
      "source": [
        "unbalanced_reviews_train_set, unbalanced_reviews_test_set = get_unbalanced_set(reviews, negative_sentiment_train_size=90, positive_sentiment_train_size=900)\n",
        "\n",
        "unbalanced_processed_train_set, unbalanced_processed_test_set = ignore_unseen_words_second(unbalanced_reviews_train_set, unbalanced_reviews_test_set)\n",
        "print('Vocab size of test_set before removing unseen words:', vocab_size(unbalanced_reviews_test_set))\n",
        "print('Vocab size of test_set after removing unseen words:', vocab_size(unbalanced_processed_test_set))\n",
        "\n",
        "print(\"Training NB on the unbalanced dataset without smoothing ......\")\n",
        "actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len = train_NB_second(unbalanced_processed_train_set, k_smoothing=None)\n",
        "\n",
        "\n",
        "print(\"Testing NB on the unbalanced dataset without smoothing ......\")\n",
        "test_predictions = test_NB_second(unbalanced_processed_test_set, actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len, unique_tokens=True, k_smoothing=None)\n",
        "test_true_labels = return_true_labels(unbalanced_processed_test_set)\n",
        "accuracy = calculate_accuracy(test_predictions, test_true_labels)\n",
        "print(f\"NB classification Accuracy: {100*accuracy}% on the unbalanced dataset with unique tokens\")\n",
        "\n",
        "test_predictions = test_NB_second(unbalanced_processed_test_set, actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len, unique_tokens=False, k_smoothing=None)\n",
        "test_true_labels = return_true_labels(unbalanced_processed_test_set)\n",
        "accuracy = calculate_accuracy(test_predictions, test_true_labels)\n",
        "print(f\"NB classification Accuracy: {100*accuracy}% on the unbalanced dataset without unique tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wJzcHX3WUDm"
      },
      "source": [
        "## Smoothing (1pt)\n",
        "\n",
        "As mentioned above, the presence of words in the test dataset that\n",
        "have not been seen during training can cause probabilities in the Naive\n",
        "Bayes classifier to be $0$, thus making that particular test instance\n",
        "undecidable. The standard way to mitigate this effect (as well as to\n",
        "give more clout to rare words) is to use smoothing, in which the\n",
        "probability fraction\n",
        "$$\\frac{\\text{count}(w_i, c)}{\\sum\\limits_{w\\in V} \\text{count}(w, c)}$$ for a word\n",
        "$w_i$ becomes\n",
        "$$\\frac{\\text{count}(w_i, c) + \\text{smoothing}(w_i)}{\\sum\\limits_{w\\in V} \\text{count}(w, c) + \\sum\\limits_{w \\in V} \\text{smoothing}(w)}$$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBNIcbwUWphC"
      },
      "source": [
        "#### (Q2.4) Implement Laplace feature smoothing (1pt)\n",
        "Implement Laplace smoothing, i.e., smoothing with a constant value ($smoothing(w) = \\kappa, \\forall w \\in V$), in your Naive\n",
        "Bayes classifier’s code, and report the accuracy.\n",
        "Use $\\kappa = 1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "bQB78brlm3ph",
        "outputId": "754ddb42-9e35-4d90-df47-b88f8707846f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training NB with smoothing on balanced dataset...... without removing unseen words\n",
            "Testing NB with smoothing ...... without removing unseen words\n",
            "NB classification accuracy: 85.5% with unique tokens\n",
            "NB classification accuracy: 82.5% without unique tokens\n"
          ]
        }
      ],
      "source": [
        "reviews_train_set, reviews_test_set = get_train_test_set(reviews, train_size_per_sentiment=900)\n",
        "\n",
        "print(\"Training NB with smoothing on balanced dataset...... without removing unseen words\")\n",
        "actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len = train_NB_second(reviews_train_set, k_smoothing=1)\n",
        "\n",
        "print(\"Testing NB with smoothing ...... without removing unseen words\")\n",
        "test_predictions = test_NB_second(reviews_test_set, actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len, unique_tokens=True, k_smoothing=1, remove_words=False)\n",
        "test_true_labels = return_true_labels(reviews_test_set)\n",
        "accuracy = calculate_accuracy(test_predictions, test_true_labels)\n",
        "print(f\"NB classification accuracy: {100*accuracy}% with unique tokens\")\n",
        "\n",
        "test_predictions = test_NB_second(reviews_test_set, actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len, unique_tokens=False, k_smoothing=1, remove_words=False)\n",
        "accuracy = calculate_accuracy(test_predictions, test_true_labels)\n",
        "print(f\"NB classification accuracy: {100*accuracy}% without unique tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "g03yflCc9kpW",
        "outputId": "872c4291-c998-4dec-c69f-1655ea870f3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size of test_set before removing unseen words: 14812\n",
            "Vocab size of test_set after removing unseen words: 12417\n",
            "Training NB with smoothing on balanced dataset......\n",
            "Testing NB with smoothing ......\n",
            "NB classification accuracy: 86.5% with unique tokens\n",
            "NB classification accuracy: 83.5% without unique tokens\n"
          ]
        }
      ],
      "source": [
        "reviews_train_set, reviews_test_set = get_train_test_set(reviews, train_size_per_sentiment=900)\n",
        "processed_train_set, processed_test_set = ignore_unseen_words_second(reviews_train_set, reviews_test_set)\n",
        "print('Vocab size of test_set before removing unseen words:', vocab_size(reviews_test_set))\n",
        "print('Vocab size of test_set after removing unseen words:', vocab_size(processed_test_set))\n",
        "\n",
        "\n",
        "print(\"Training NB with smoothing on balanced dataset......\")\n",
        "actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len = train_NB_second(processed_train_set, k_smoothing=1)\n",
        "\n",
        "print(\"Testing NB with smoothing ......\")\n",
        "test_predictions = test_NB_second(processed_test_set, actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len, unique_tokens=True, k_smoothing=1)\n",
        "test_true_labels = return_true_labels(processed_test_set)\n",
        "accuracy = calculate_accuracy(test_predictions, test_true_labels)\n",
        "print(f\"NB classification accuracy: {100*accuracy}% with unique tokens\")\n",
        "\n",
        "test_predictions = test_NB_second(processed_test_set, actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len, unique_tokens=False, k_smoothing=1)\n",
        "accuracy = calculate_accuracy(test_predictions, test_true_labels)\n",
        "print(f\"NB classification accuracy: {100*accuracy}% without unique tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiGcgwba87D5"
      },
      "source": [
        "## Cross-Validation (1.5pts)\n",
        "\n",
        "A serious danger in using Machine Learning on small datasets, with many\n",
        "iterations of slightly different versions of the algorithms, is ending up with Type III errors, also called the “testing hypotheses\n",
        "suggested by the data” errors. This type of error occurs when we make\n",
        "repeated improvements to our classifiers by playing with features and\n",
        "their processing, but we don’t get a fresh, never-before seen test\n",
        "dataset every time. Thus, we risk developing a classifier that gets better\n",
        "and better on our data, but only gets worse at generalizing to new, unseen data. In other words, we risk developping a classifier that overfits.\n",
        "\n",
        "A simple method to guard against Type III errors is to use\n",
        "Cross-Validation. In **N-fold Cross-Validation**, we divide the data into N\n",
        "distinct chunks, or folds. Then, we repeat the experiment N times: each\n",
        "time holding out one of the folds for testing, training our classifier\n",
        "on the remaining N - 1 data folds, and reporting performance on the\n",
        "held-out fold. We can use different strategies for dividing the data:\n",
        "\n",
        "-   Consecutive splitting:\n",
        "  - cv000–cv099 = Split 1\n",
        "  - cv100–cv199 = Split 2\n",
        "  - etc.\n",
        "  \n",
        "-   Round-robin splitting (mod 10):\n",
        "  - cv000, cv010, cv020, … = Split 1\n",
        "  - cv001, cv011, cv021, … = Split 2\n",
        "  - etc.\n",
        "\n",
        "-   Random sampling/splitting\n",
        "  - Not used here (but you may choose to split this way in a non-educational situation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OeLcbSauGtR"
      },
      "source": [
        "#### (Q2.5) Write the code to implement 10-fold cross-validation using round-robin splitting for your Naive Bayes classifier from Q2.4 and compute the 10 accuracies. Report the final performance, which is the average of the performances per fold. If all splits perform equally well, this is a good sign. (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3KeCGPa7Nuzx"
      },
      "outputs": [],
      "source": [
        "def k_fold_round_robin_split(reviews, k=10):\n",
        "    \"\"\"Splits the reviews into k splits using a round-robin algorithm\"\"\"\n",
        "    splits = [[] for _ in range(k)]\n",
        "    for i, review in enumerate(reviews):\n",
        "        splits[i % k].append(review)\n",
        "    for i in range(k):\n",
        "        test_set = splits[i]\n",
        "        train_set = []\n",
        "        for j in range(k):\n",
        "            if j != i:\n",
        "                train_set += splits[j]\n",
        "        yield train_set, test_set\n",
        "\n",
        "def k_fold_cross_validation(reviews, k):\n",
        "    \"\"\"Trains the NB classifier using k-fold cross-validation, instead of held out apporach\n",
        "    Returns the accuracy per fold for k-fold cross validation\"\"\"\n",
        "    accuracy_per_fold_unique, accuracy_per_fold = [], []\n",
        "    gen = k_fold_round_robin_split(reviews, k=k)\n",
        "    print(\"Starting k-fold cross validation ......\")\n",
        "    for fold in range(k):\n",
        "        print(\"-------------------------------------------------------\")\n",
        "        train_set, test_set = next(gen)\n",
        "        processed_train_set, processed_test_set = ignore_unseen_words_second(train_set, test_set)\n",
        "\n",
        "        actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len = train_NB_second(processed_train_set, k_smoothing=1)\n",
        "\n",
        "        test_predictions = test_NB_second(processed_test_set, actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len, unique_tokens=True, k_smoothing=1)\n",
        "        test_true_labels = return_true_labels(processed_test_set)\n",
        "        accuracy = calculate_accuracy(test_predictions, test_true_labels)\n",
        "        accuracy_per_fold_unique.append(accuracy)\n",
        "        print(f\"NB classification accuracy: {100*accuracy}% in fold {fold+1} using unique tokens\")\n",
        "\n",
        "        test_predictions = test_NB_second(processed_test_set, actual_vocab, class_prior_prob, class_cond_prob, total_freq_per_class, vocab_len, unique_tokens=False, k_smoothing=1)\n",
        "        accuracy = calculate_accuracy(test_predictions, test_true_labels)\n",
        "        accuracy_per_fold.append(accuracy)\n",
        "        print(f\"NB classification accuracy: {100*accuracy}% in fold {fold+1} without using unique tokens\")\n",
        "        print(\"-------------------------------------------------------\")\n",
        "    print(f'Recap: Accuracy per fold: {100*accuracy_per_fold_unique} using unique tokens')\n",
        "    print(f'Recap: Accuracy per fold: {100*accuracy_per_fold} without using unique tokens')\n",
        "    print(f\"Average accuracy over {k} folds: {np.mean(100*accuracy_per_fold_unique)}% using unique tokens\")\n",
        "    print(f\"Average accuracy over {k} folds: {np.mean(100*accuracy_per_fold)}% without using unique tokens\")\n",
        "    return accuracy_per_fold_unique, accuracy_per_fold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "6WMI8nJDm3ph",
        "outputId": "8ee41609-ac60-4ca2-98e1-1aebae79d537",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------\n",
            "Vanilla NB with k-fold cross validation\n",
            "Starting k-fold cross validation ......\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 80.0% in fold 1 using unique tokens\n",
            "NB classification accuracy: 78.5% in fold 1 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 86.5% in fold 2 using unique tokens\n",
            "NB classification accuracy: 85.0% in fold 2 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 80.0% in fold 3 using unique tokens\n",
            "NB classification accuracy: 81.0% in fold 3 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 87.5% in fold 4 using unique tokens\n",
            "NB classification accuracy: 87.5% in fold 4 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 78.5% in fold 5 using unique tokens\n",
            "NB classification accuracy: 81.0% in fold 5 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 86.0% in fold 6 using unique tokens\n",
            "NB classification accuracy: 86.5% in fold 6 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 80.5% in fold 7 using unique tokens\n",
            "NB classification accuracy: 82.5% in fold 7 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 80.5% in fold 8 using unique tokens\n",
            "NB classification accuracy: 78.5% in fold 8 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 84.0% in fold 9 using unique tokens\n",
            "NB classification accuracy: 82.5% in fold 9 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 80.0% in fold 10 using unique tokens\n",
            "NB classification accuracy: 82.5% in fold 10 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "Recap: Accuracy per fold: [0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8, 0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8] using unique tokens\n",
            "Recap: Accuracy per fold: [0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825, 0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825] without using unique tokens\n",
            "Average accuracy over 10 folds: 0.8235% using unique tokens\n",
            "Average accuracy over 10 folds: 0.8255% without using unique tokens\n",
            "------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print('------------------------------------------------')\n",
        "print('Vanilla NB with k-fold cross validation')\n",
        "accuracy_per_fold_unique, accuracy_per_fold = k_fold_cross_validation(reviews, k=10)\n",
        "print('------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "i6xKCc89m3pi",
        "outputId": "a5782537-f335-470a-8872-dfd7450189e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing the list with accuracies: [0.8, 0.865, 0.8, 0.875, 0.785, 0.86, 0.805, 0.805, 0.84, 0.8] with unique tokens\n",
            "Printing the list with accuracies: [0.785, 0.85, 0.81, 0.875, 0.81, 0.865, 0.825, 0.785, 0.825, 0.825] without unique tokens\n"
          ]
        }
      ],
      "source": [
        "print(f\"Printing the list with accuracies: {accuracy_per_fold_unique} with unique tokens\")\n",
        "print(f\"Printing the list with accuracies: {accuracy_per_fold} without unique tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otdlsDXBNyOa"
      },
      "source": [
        "#### (Q2.6) Report the variance of the 10 accuracy scores. (0.5pt)\n",
        "\n",
        "**Please report all future results using 10-fold cross-validation now\n",
        "(unless told to use the held-out test set).** Note: you're not allowed to use a library for computing the variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ZoBQm1KuNzNR",
        "outputId": "0eada052-4e53-4f39-8f9f-ad7919dbd0a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variance of the 10 accuracy scores: 0.0009802499999999985 using unique tokens\n",
            "Variance of the 10 accuracy scores: 0.0008372499999999991 without using unique tokens\n",
            "Using numpy for cross-validation\n",
            "Numpy Variance of the 10 accuracy scores: 0.0009802499999999985 using unique tokens\n",
            "Numpy Variance of the 10 accuracy scores: 0.0008372499999999991 without using unique tokens\n"
          ]
        }
      ],
      "source": [
        "def compute_variance(accuracy_per_fold):\n",
        "    mean = sum(accuracy_per_fold) / len(accuracy_per_fold)\n",
        "    variance = sum((x - mean) ** 2 for x in accuracy_per_fold) / len(accuracy_per_fold)\n",
        "    return variance\n",
        "\n",
        "variance_unique = compute_variance(accuracy_per_fold_unique)\n",
        "variance = compute_variance(accuracy_per_fold)\n",
        "print(f\"Variance of the 10 accuracy scores: {variance_unique} using unique tokens\")\n",
        "print(f\"Variance of the 10 accuracy scores: {variance} without using unique tokens\")\n",
        "\n",
        "print('Using numpy for cross-validation')\n",
        "print(f'Numpy Variance of the 10 accuracy scores: {np.var(accuracy_per_fold_unique)} using unique tokens')\n",
        "print(f'Numpy Variance of the 10 accuracy scores: {np.var(accuracy_per_fold)} without using unique tokens')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6A2zX9_BRKm"
      },
      "source": [
        "## Features, overfitting, and the curse of dimensionality\n",
        "\n",
        "In the Bag-of-Words model, ideally we would like each distinct word in\n",
        "the text to be mapped to its own dimension in the output vector\n",
        "representation. However, real world text is messy, and we need to decide\n",
        "on what we consider to be a word. For example, is “`word`\" different\n",
        "from “`Word`\", from “`word`”, or from “`words`\"? Too strict a\n",
        "definition, and the number of features explodes, while our algorithm\n",
        "fails to learn anything generalisable. Too lax, and we risk destroying\n",
        "our learning signal. In the following section, you will learn about\n",
        "confronting the feature sparsity and the overfitting problems as they\n",
        "occur in NLP classification tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKK8FNt8VtcZ"
      },
      "source": [
        "### Stemming (1.5pts)\n",
        "\n",
        "To make your algorithm more robust, use stemming and hash different inflections of a word to the same feature in the BoW vector space. Please use the [Porter stemming\n",
        "    algorithm](http://www.nltk.org/howto/stem.html) from NLTK.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NxtCul1IrBi_"
      },
      "outputs": [],
      "source": [
        "def apply_stemming(reviews):\n",
        "    \"\"\"Returns the reviews with the tokens stemmed\"\"\"\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_reviews = copy.deepcopy(reviews)\n",
        "    for review in stemmed_reviews:\n",
        "        for sentence in review[\"content\"]:\n",
        "            for i, (token, pos_tag) in enumerate(sentence):\n",
        "                sentence[i] = (stemmer.stem(token, to_lowercase=True), pos_tag)\n",
        "    return stemmed_reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SrJ1BeLXTnk"
      },
      "source": [
        "#### (Q2.7): How does the performance of your classifier change when you use stemming on your training and test datasets? (1pt)\n",
        "Use cross-validation to evaluate the classifier.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8prZO37m3pi"
      },
      "source": [
        "**Answer Q2.7**:\n",
        "\n",
        "Using the stemming method did not have a significant impact on the acquired classification accuracy of the classifier. The average accuracy of stemming with NB on the cross-fold validation was $\\approx 0.8\\%$ lower than the vanilla NB classifier.\n",
        "\n",
        "**(Maybe include why this is the case)**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "gYqKBOiIrInT",
        "outputId": "2f41ca13-9b52-4f04-9be4-b3a1498bb5a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------\n",
            "NB with stemming with k-fold cross validation\n",
            "Starting k-fold cross validation ......\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 81.0% in fold 1 using unique tokens\n",
            "NB classification accuracy: 77.0% in fold 1 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 84.0% in fold 2 using unique tokens\n",
            "NB classification accuracy: 83.5% in fold 2 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 79.0% in fold 3 using unique tokens\n",
            "NB classification accuracy: 80.5% in fold 3 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 88.0% in fold 4 using unique tokens\n",
            "NB classification accuracy: 87.5% in fold 4 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 76.5% in fold 5 using unique tokens\n",
            "NB classification accuracy: 79.0% in fold 5 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 83.5% in fold 6 using unique tokens\n",
            "NB classification accuracy: 84.5% in fold 6 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 80.5% in fold 7 using unique tokens\n",
            "NB classification accuracy: 80.5% in fold 7 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 81.0% in fold 8 using unique tokens\n",
            "NB classification accuracy: 79.0% in fold 8 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 85.0% in fold 9 using unique tokens\n",
            "NB classification accuracy: 82.0% in fold 9 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 81.5% in fold 10 using unique tokens\n",
            "NB classification accuracy: 83.5% in fold 10 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "Recap: Accuracy per fold: [0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815, 0.81, 0.84, 0.79, 0.88, 0.765, 0.835, 0.805, 0.81, 0.85, 0.815] using unique tokens\n",
            "Recap: Accuracy per fold: [0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835, 0.77, 0.835, 0.805, 0.875, 0.79, 0.845, 0.805, 0.79, 0.82, 0.835] without using unique tokens\n",
            "Average accuracy over 10 folds: 0.82% using unique tokens\n",
            "Average accuracy over 10 folds: 0.817% without using unique tokens\n",
            "------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print('------------------------------------------------')\n",
        "print('NB with stemming with k-fold cross validation')\n",
        "stemmed_reviews = apply_stemming(reviews)\n",
        "stemmed_accuracy_per_fold_unique, stemmed_accuracy_per_fold = k_fold_cross_validation(stemmed_reviews, k=10)\n",
        "print('------------------------------------------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkDHVq_1XUVP"
      },
      "source": [
        "#### (Q2.8) What happens to the number of features (i.e., the size of the vocabulary) when using stemming as opposed to (Q2.4)? (0.5pt)\n",
        "Give actual numbers. You can use the held-out training set to determine these."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "gDmpbM1Lm3pj"
      },
      "outputs": [],
      "source": [
        "def count_features(input_set):\n",
        "    \"\"\"Returns a set of unique tokens from all the sentences of the input set\"\"\"\n",
        "    return len(set(token.lower() for review in input_set for sentence in review[\"content\"] for token, _ in sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "MA3vee5-rJyy",
        "outputId": "dd7aa3cd-9486-40c5-92de-adb448b61ff8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num. of features in NB without using stemming: 45348, before removing case2 unseen words\n",
            "Num. of features in NB without using stemming: 18799, after removing case2 unseen words\n",
            "------------------------------------------------\n",
            "Num. of features in NB using stemming: 32404, before removing case2 unseen words\n",
            "Num. of features in NB using stemming: 13326, after removing case2 unseen words\n"
          ]
        }
      ],
      "source": [
        "print(f\"Num. of features in NB without using stemming: {count_features(reviews_train_set)}, before removing case2 unseen words\")\n",
        "\n",
        "\n",
        "print(f\"Num. of features in NB without using stemming: {count_features(processed_train_set)}, after removing case2 unseen words\")\n",
        "print('------------------------------------------------')\n",
        "stemmed_train_set, stemmed_test_set = get_train_test_set(stemmed_reviews, train_size_per_sentiment=900)\n",
        "print(f\"Num. of features in NB using stemming: {count_features(stemmed_train_set)}, before removing case2 unseen words\")\n",
        "stemmed_processed_train_set, _ = ignore_unseen_words_second(stemmed_train_set, stemmed_test_set)\n",
        "print(f\"Num. of features in NB using stemming: {count_features(stemmed_processed_train_set)}, after removing case2 unseen words\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoazfxbNV5Lq"
      },
      "source": [
        "### N-grams (1.5pts)\n",
        "\n",
        "A simple way of retaining some of the word\n",
        "order information when using bag-of-words representations is to use **n-gram** features.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHjy3I7-qWiu"
      },
      "source": [
        "#### (Q2.9) Retrain your classifier from (Q2.4) using **unigrams+bigrams** and **unigrams+bigrams+trigrams** as features. (1pt)\n",
        "Report accuracy and compare it with that of the approaches you have previously implemented. You are allowed to use NLTK to build n-grams from sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "eYuKMTOpq9jz"
      },
      "outputs": [],
      "source": [
        "def reviews_ngrams(reviews, n):\n",
        "    ngrammed_reviews = copy.deepcopy(reviews)\n",
        "    for review in ngrammed_reviews:\n",
        "        for sentence in review[\"content\"]:\n",
        "            ngrams_sentences = []\n",
        "            for n_actual in range(2, n+1):\n",
        "                sentence_tokens, sentence_pos = zip(*sentence)\n",
        "                sentence_tokens_ngrams = ngrams(sentence_tokens, n_actual)\n",
        "                sentence_pos_ngrams = ngrams(sentence_pos, n_actual)\n",
        "                sentence_ngrams = [[], []]\n",
        "                sentence_ngrams[0].extend([' '.join(tokens) for tokens in sentence_tokens_ngrams])\n",
        "                sentence_ngrams[1].extend([' '.join(pos) for pos in sentence_pos_ngrams])\n",
        "                ngrams_sentences.extend([list(x) for x in zip(*sentence_ngrams)])\n",
        "            sentence.extend(ngram_ for ngram_ in ngrams_sentences)\n",
        "\n",
        "    return ngrammed_reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "KCoE10Lam3pk",
        "outputId": "4ab47472-2a6d-48f9-e755-d9e9770ae64b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------\n",
            "NB with bigrams with k-fold cross validation\n",
            "Starting k-fold cross validation ......\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 79.0% in fold 1 using unique tokens\n",
            "NB classification accuracy: 75.5% in fold 1 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 84.5% in fold 2 using unique tokens\n",
            "NB classification accuracy: 83.0% in fold 2 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 86.0% in fold 3 using unique tokens\n",
            "NB classification accuracy: 83.0% in fold 3 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 91.0% in fold 4 using unique tokens\n",
            "NB classification accuracy: 87.5% in fold 4 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 80.5% in fold 5 using unique tokens\n",
            "NB classification accuracy: 82.0% in fold 5 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 84.5% in fold 6 using unique tokens\n",
            "NB classification accuracy: 84.0% in fold 6 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 84.5% in fold 7 using unique tokens\n",
            "NB classification accuracy: 84.5% in fold 7 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 84.0% in fold 8 using unique tokens\n",
            "NB classification accuracy: 81.0% in fold 8 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 86.0% in fold 9 using unique tokens\n",
            "NB classification accuracy: 84.5% in fold 9 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 86.0% in fold 10 using unique tokens\n",
            "NB classification accuracy: 82.0% in fold 10 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "Recap: Accuracy per fold: [0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86, 0.79, 0.845, 0.86, 0.91, 0.805, 0.845, 0.845, 0.84, 0.86, 0.86] using unique tokens\n",
            "Recap: Accuracy per fold: [0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82, 0.755, 0.83, 0.83, 0.875, 0.82, 0.84, 0.845, 0.81, 0.845, 0.82] without using unique tokens\n",
            "Average accuracy over 10 folds: 0.846% using unique tokens\n",
            "Average accuracy over 10 folds: 0.8270000000000001% without using unique tokens\n",
            "------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print('------------------------------------------------')\n",
        "print('NB with bigrams with k-fold cross validation')\n",
        "bigrams_reviews = reviews_ngrams(reviews, n=2)\n",
        "ngrammed_accuracy_per_fold_unique, ngrammed_accuracy_per_fold = k_fold_cross_validation(bigrams_reviews, k=10)\n",
        "print('------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "06yGVW9Hm3pk",
        "outputId": "d1cb8a5c-4af1-45d7-9d44-bcde1a752a84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------\n",
            "NB with trigrams with k-fold cross validation\n",
            "Starting k-fold cross validation ......\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 78.5% in fold 1 using unique tokens\n",
            "NB classification accuracy: 77.0% in fold 1 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 85.0% in fold 2 using unique tokens\n",
            "NB classification accuracy: 83.0% in fold 2 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 85.0% in fold 3 using unique tokens\n",
            "NB classification accuracy: 84.0% in fold 3 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 91.0% in fold 4 using unique tokens\n",
            "NB classification accuracy: 87.0% in fold 4 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 81.5% in fold 5 using unique tokens\n",
            "NB classification accuracy: 81.0% in fold 5 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 84.5% in fold 6 using unique tokens\n",
            "NB classification accuracy: 84.0% in fold 6 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 84.0% in fold 7 using unique tokens\n",
            "NB classification accuracy: 83.5% in fold 7 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 85.0% in fold 8 using unique tokens\n",
            "NB classification accuracy: 82.0% in fold 8 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 86.5% in fold 9 using unique tokens\n",
            "NB classification accuracy: 86.0% in fold 9 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "NB classification accuracy: 88.0% in fold 10 using unique tokens\n",
            "NB classification accuracy: 82.5% in fold 10 without using unique tokens\n",
            "-------------------------------------------------------\n",
            "Recap: Accuracy per fold: [0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88, 0.785, 0.85, 0.85, 0.91, 0.815, 0.845, 0.84, 0.85, 0.865, 0.88] using unique tokens\n",
            "Recap: Accuracy per fold: [0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825, 0.77, 0.83, 0.84, 0.87, 0.81, 0.84, 0.835, 0.82, 0.86, 0.825] without using unique tokens\n",
            "Average accuracy over 10 folds: 0.849% using unique tokens\n",
            "Average accuracy over 10 folds: 0.8299999999999998% without using unique tokens\n",
            "------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print('------------------------------------------------')\n",
        "print('NB with trigrams with k-fold cross validation')\n",
        "trigrams_reviews = reviews_ngrams(reviews, n=3)\n",
        "ngrammed_accuracy_per_fold_unique, ngrammed_accuracy_per_fold = k_fold_cross_validation(trigrams_reviews, k=10)\n",
        "print('------------------------------------------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVrGGArkrWoL"
      },
      "source": [
        "\n",
        "#### Q2.10: How many features does the BoW model have to take into account now? (0.5pt)\n",
        "How would you expect the number of features to increase theoretically (e.g., linear, square, cubed, exponential)? How does this number compare, in practice, to the number of features at (Q2.8)?\n",
        "\n",
        "Use the held-out training set once again for this.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEGZ9SV8pPaa"
      },
      "source": [
        "**Answer Q2.10**:\n",
        "\n",
        "In the lectures when we considered the Tabular parameterisations of Ngrams Language Model (LM) we proved that the size of tabular represenation of the history-conditioned word  distribution $P(W|H)$ ,  increases exponentialy with the size of ngrams used. In case we denote our vocabulary size with V, the size of the tabular representation would be $V$ in the case of Unigram LM. In the general case of using $n$ Ngrams LM the size fo the size of the tabular representation would be $V^{n}$ .\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_z8sAJeUrdtM",
        "outputId": "6511a3a0-e684-4667-8bc2-45886a0ccd01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num. of features in NB using unigrams+bigrams: 465262, before removing case2 unseen words\n",
            "Num. of features in unigrams+bigrams: 93655, after removing case2 unseen words\n"
          ]
        }
      ],
      "source": [
        "bigrammed_train_set, bigrammed_test_set = get_train_test_set(bigrams_reviews, train_size_per_sentiment=900)\n",
        "print(f\"Num. of features in NB using unigrams+bigrams: {count_features(bigrammed_train_set)}, before removing case2 unseen words\")\n",
        "bigrammed_processed_train_set, _ = ignore_unseen_words_second(bigrammed_train_set, bigrammed_test_set)\n",
        "print(f\"Num. of features in unigrams+bigrams: {count_features(bigrammed_processed_train_set)}, after removing case2 unseen words\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "0unb9jfAm3pl",
        "outputId": "32e52779-1709-4846-fbbe-b8a742a82e82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num. of features in NB using unigrams+bigrams+trigrams: 1346107, before removing case2 unseen words\n",
            "Num. of features in unigrams+bigrams+trigrams: 156730, after removing case2 unseen words\n"
          ]
        }
      ],
      "source": [
        "trigrammed_train_set, trigrammed_test_set = get_train_test_set(trigrams_reviews, train_size_per_sentiment=900)\n",
        "print(f\"Num. of features in NB using unigrams+bigrams+trigrams: {count_features(trigrammed_train_set)}, before removing case2 unseen words\")\n",
        "trigrammed_processed_train_set, _ = ignore_unseen_words_second(trigrammed_train_set, trigrammed_test_set)\n",
        "print(f\"Num. of features in unigrams+bigrams+trigrams: {count_features(trigrammed_processed_train_set)}, after removing case2 unseen words\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHWKDL3YV6vh"
      },
      "source": [
        "# (3) Support Vector Machines (4pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJSYhcVaoJGt"
      },
      "source": [
        "Though simple to understand, implement, and debug, one\n",
        "major problem with the Naive Bayes classifier is that its performance\n",
        "deteriorates (becomes skewed) when it is being used with features which\n",
        "are not independent (i.e., are correlated). Another popular classifier\n",
        "that doesn’t scale as well to big data, and is not as simple to debug as\n",
        "Naive Bayes, but that doesn’t assume feature independence is the Support\n",
        "Vector Machine (SVM) classifier.\n",
        "\n",
        "You can find more details about SVMs in Chapter 7 of Bishop: Pattern Recognition and Machine Learning.\n",
        "Other sources for learning SVM:\n",
        "* http://web.mit.edu/zoya/www/SVM.pdf\n",
        "* http://www.cs.columbia.edu/~kathy/cs4701/documents/jason_svm_tutorial.pdf\n",
        "* https://pythonprogramming.net/support-vector-machine-intro-machine-learning-tutorial/\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Use the scikit-learn implementation of\n",
        "[SVM](http://scikit-learn.org/stable/modules/svm.html) with the default parameters. (You are not expected to perform any hyperparameter tuning, but feel free to do it if you think it gives you good insights for the discussion in question 5.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LnzNtQBV8gr"
      },
      "source": [
        "#### (Q3.1): Train SVM and compare to Naive Bayes (2pts)\n",
        "\n",
        "Train an SVM classifier (sklearn.svm.LinearSVC) using the features collected for Naive Bayes. Compare the\n",
        "classification performance of the SVM classifier to that of the Naive\n",
        "Bayes classifier with smoothing.\n",
        "Use cross-validation to evaluate the performance of the classifiers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "JBscui8Mvoz0",
        "outputId": "dff52a9b-8825-499c-ea5b-9b70cb2241aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting k-fold cross validation ......\n",
            "-------------------------------------------------------\n",
            "SVM classification accuracy: 81.0% in fold 0\n",
            "SVM classification P: 80.39% in fold 0\n",
            "SVM classification R: 82.0% in fold 0\n",
            "SVM classification F1: 81.19% in fold 0\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "SVM classification accuracy: 79.5% in fold 1\n",
            "SVM classification P: 80.41% in fold 1\n",
            "SVM classification R: 78.0% in fold 1\n",
            "SVM classification F1: 79.19% in fold 1\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 80.0% in fold 2\n",
            "SVM classification P: 80.0% in fold 2\n",
            "SVM classification R: 80.0% in fold 2\n",
            "SVM classification F1: 80.0% in fold 2\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 84.0% in fold 3\n",
            "SVM classification P: 84.69% in fold 3\n",
            "SVM classification R: 83.0% in fold 3\n",
            "SVM classification F1: 83.84% in fold 3\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "SVM classification accuracy: 85.0% in fold 4\n",
            "SVM classification P: 85.0% in fold 4\n",
            "SVM classification R: 85.0% in fold 4\n",
            "SVM classification F1: 85.0% in fold 4\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 81.5% in fold 5\n",
            "SVM classification P: 81.82% in fold 5\n",
            "SVM classification R: 81.0% in fold 5\n",
            "SVM classification F1: 81.41% in fold 5\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 85.0% in fold 6\n",
            "SVM classification P: 85.71% in fold 6\n",
            "SVM classification R: 84.0% in fold 6\n",
            "SVM classification F1: 84.85% in fold 6\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 85.0% in fold 7\n",
            "SVM classification P: 85.0% in fold 7\n",
            "SVM classification R: 85.0% in fold 7\n",
            "SVM classification F1: 85.0% in fold 7\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 87.5% in fold 8\n",
            "SVM classification P: 89.47% in fold 8\n",
            "SVM classification R: 85.0% in fold 8\n",
            "SVM classification F1: 87.18% in fold 8\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "SVM classification accuracy: 84.0% in fold 9\n",
            "SVM classification P: 85.42% in fold 9\n",
            "SVM classification R: 82.0% in fold 9\n",
            "SVM classification F1: 83.67% in fold 9\n",
            "-------------------------------------------------------\n",
            "Recap: Accuracy per fold: [0.81, 0.795, 0.8, 0.84, 0.85, 0.815, 0.85, 0.85, 0.875, 0.84]\n",
            "Recap: P per fold: [0.82, 0.78, 0.8, 0.83, 0.85, 0.81, 0.84, 0.85, 0.85, 0.82]\n",
            "Recap: R per fold: [0.803921568627451, 0.8041237113402062, 0.8, 0.8469387755102041, 0.85, 0.8181818181818182, 0.8571428571428571, 0.85, 0.8947368421052632, 0.8541666666666666]\n",
            "Recap: F1 per fold: [0.8118811881188118, 0.7918781725888325, 0.8000000000000002, 0.8383838383838385, 0.85, 0.8140703517587939, 0.8484848484848485, 0.85, 0.8717948717948718, 0.836734693877551]\n",
            "Average accuracy over 10 folds: 83.25%\n",
            "Average P over 10 folds: 83.79%\n",
            "Average R over 10 folds: 82.5%\n",
            "Average F1 over 10 folds: 83.13%\n"
          ]
        }
      ],
      "source": [
        "def find_measurments(predict_labels,true_labels):\n",
        "    FP,TP,FN,TN=(0,0,0,0)\n",
        "    for predict,true in zip(predict_labels,true_labels):\n",
        "        if predict==\"POS\" and true==\"POS\":\n",
        "            TP+=1\n",
        "        elif predict==\"POS\" and true==\"NEG\":\n",
        "            FP+=1\n",
        "        elif predict==\"NEG\" and true==\"POS\":\n",
        "            FN+=1\n",
        "        elif predict==\"NEG\" and true==\"NEG\":\n",
        "            TN+=1\n",
        "    accuracy= (TP+TN)/(FP+TP+FN+TN)\n",
        "    P=TP/(TP+FP)\n",
        "    R=TP/(TP+FN)\n",
        "    F1 =(2*P*R)/(P+R)\n",
        "    return accuracy,P,R,F1\n",
        "def k_fold_round_robin_split_svm(reviews, k=10):\n",
        "    \"\"\"Splits the reviews into k splits using a round-robin algorithm\"\"\"\n",
        "    splits = [[] for _ in range(k)]\n",
        "    for i, review in enumerate(reviews):\n",
        "        splits[i % k].append(review)\n",
        "    for i in range(k):\n",
        "        test_set = splits[i]\n",
        "        train_set = []\n",
        "        for j in range(k):\n",
        "            if j != i:\n",
        "                train_set += splits[j]\n",
        "        yield train_set, test_set\n",
        "def k_fold_cross_validation_svm(reviews,extract_back_of_words,make_histogram, k):\n",
        "    accuracy_per_fold,P_per_fold,R_per_fold,F1_per_fold = [],[],[],[]\n",
        "    gen = k_fold_round_robin_split_svm(reviews, k=k)\n",
        "    print(\"Starting k-fold cross validation ......\")\n",
        "    for fold in range(k):\n",
        "        print(\"-------------------------------------------------------\")\n",
        "        train_set, test_set = next(gen)\n",
        "        back_of_words=extract_back_of_words([i[\"content\"] for i in train_set])\n",
        "        histogram_train=make_histogram([i[\"content\"] for i in train_set],back_of_words)\n",
        "        clf=sk.svm.LinearSVC()\n",
        "        clf.fit(histogram_train,np.array([i[\"sentiment\"] for i in train_set]).reshape(-1,1).ravel())\n",
        "        histogram_test=make_histogram([i[\"content\"] for i in test_set],back_of_words)\n",
        "        predict_labels=clf.predict(histogram_test)\n",
        "        accuracy,P,R,F1=find_measurments(predict_labels,[i[\"sentiment\"] for i in test_set])\n",
        "        accuracy_per_fold.append(accuracy)\n",
        "        P_per_fold.append(P)\n",
        "        R_per_fold.append(R)\n",
        "        F1_per_fold.append(F1)\n",
        "        print(f\"SVM classification accuracy: {np.round(100*accuracy,2)}% in fold {fold}\")\n",
        "        print(f\"SVM classification P: {np.round(100*P,2)}% in fold {fold}\")\n",
        "        print(f\"SVM classification R: {np.round(100*R,2)}% in fold {fold}\")\n",
        "        print(f\"SVM classification F1: {np.round(100*F1,2)}% in fold {fold}\")\n",
        "        print(\"-------------------------------------------------------\")\n",
        "    print(f'Recap: Accuracy per fold: {accuracy_per_fold}')\n",
        "    print(f'Recap: P per fold: {R_per_fold}')\n",
        "    print(f'Recap: R per fold: {P_per_fold}')\n",
        "    print(f'Recap: F1 per fold: {F1_per_fold}')\n",
        "    print(f\"Average accuracy over {k} folds: {np.round(100*np.mean(accuracy_per_fold),2)}%\")\n",
        "    print(f\"Average P over {k} folds: {np.round(100*np.mean(P_per_fold),2)}%\")\n",
        "    print(f\"Average R over {k} folds: {np.round(100*np.mean(R_per_fold),2)}%\")\n",
        "    print(f\"Average F1 over {k} folds: {np.round(100*np.mean(F1_per_fold),2)}%\")\n",
        "    return accuracy_per_fold,P_per_fold,R_per_fold,F1_per_fold\n",
        "\n",
        "def extract_back_of_words_1st(reviews):\n",
        "    stemmer = PorterStemmer()\n",
        "    words=set()\n",
        "    for i in reviews:\n",
        "        for line in i:\n",
        "            for word,tag in line:\n",
        "                words.add(word.lower())\n",
        "    back_of_words={}\n",
        "    for i,word in enumerate(words):\n",
        "        back_of_words[word]=i\n",
        "    return back_of_words\n",
        "\n",
        "def make_histogram_1st(reviews,back_of_words):\n",
        "    stemmer = PorterStemmer()\n",
        "    histogram=np.zeros((len(reviews),len(back_of_words)))\n",
        "    for index,r in enumerate(reviews):\n",
        "        for line in r:\n",
        "            for word,tag in line:\n",
        "                if word.lower() in back_of_words.keys():\n",
        "                    histogram[index][back_of_words[word.lower()]]+=1\n",
        "    return histogram\n",
        "accuracy_per_fold,P_per_fold,R_per_fold,F1_per_fold = k_fold_cross_validation_svm(reviews,extract_back_of_words_1st,make_histogram_1st, k=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifXVWcK0V9qY"
      },
      "source": [
        "### POS disambiguation (2pts)\n",
        "\n",
        "Now add in part-of-speech features. You will find the\n",
        "movie review dataset has already been POS-tagged for you ([here](https://catalog.ldc.upenn.edu/docs/LDC99T42/tagguid1.pdf) you find the tagset). Try to\n",
        "replicate the results obtained by Pang et al. (2002).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA3I82o4oWGu"
      },
      "source": [
        "####(Q3.2) Replace your features with word+POS features, and report performance with the SVM. Use cross-validation to evaluate the classifier and compare the results with (Q3.1). Does part-of-speech information help? Explain why this may be the case. (1pt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "NOvjYe-t2Br6",
        "outputId": "b3ea611d-dccc-482b-c4a3-8aed38d20fdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting k-fold cross validation ......\n",
            "-------------------------------------------------------\n",
            "SVM classification accuracy: 82.0% in fold 0\n",
            "SVM classification P: 80.77% in fold 0\n",
            "SVM classification R: 84.0% in fold 0\n",
            "SVM classification F1: 82.35% in fold 0\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 79.5% in fold 1\n",
            "SVM classification P: 79.8% in fold 1\n",
            "SVM classification R: 79.0% in fold 1\n",
            "SVM classification F1: 79.4% in fold 1\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 82.5% in fold 2\n",
            "SVM classification P: 82.83% in fold 2\n",
            "SVM classification R: 82.0% in fold 2\n",
            "SVM classification F1: 82.41% in fold 2\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 84.0% in fold 3\n",
            "SVM classification P: 83.33% in fold 3\n",
            "SVM classification R: 85.0% in fold 3\n",
            "SVM classification F1: 84.16% in fold 3\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 84.0% in fold 4\n",
            "SVM classification P: 86.17% in fold 4\n",
            "SVM classification R: 81.0% in fold 4\n",
            "SVM classification F1: 83.51% in fold 4\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 84.5% in fold 5\n",
            "SVM classification P: 84.16% in fold 5\n",
            "SVM classification R: 85.0% in fold 5\n",
            "SVM classification F1: 84.58% in fold 5\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 85.5% in fold 6\n",
            "SVM classification P: 85.15% in fold 6\n",
            "SVM classification R: 86.0% in fold 6\n",
            "SVM classification F1: 85.57% in fold 6\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 85.5% in fold 7\n",
            "SVM classification P: 84.47% in fold 7\n",
            "SVM classification R: 87.0% in fold 7\n",
            "SVM classification F1: 85.71% in fold 7\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "SVM classification accuracy: 86.5% in fold 8\n",
            "SVM classification P: 86.14% in fold 8\n",
            "SVM classification R: 87.0% in fold 8\n",
            "SVM classification F1: 86.57% in fold 8\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "SVM classification accuracy: 84.0% in fold 9\n",
            "SVM classification P: 87.78% in fold 9\n",
            "SVM classification R: 79.0% in fold 9\n",
            "SVM classification F1: 83.16% in fold 9\n",
            "-------------------------------------------------------\n",
            "Recap: Accuracy per fold: [0.82, 0.795, 0.825, 0.84, 0.84, 0.845, 0.855, 0.855, 0.865, 0.84]\n",
            "Recap: P per fold: [0.84, 0.79, 0.82, 0.85, 0.81, 0.85, 0.86, 0.87, 0.87, 0.79]\n",
            "Recap: R per fold: [0.8076923076923077, 0.797979797979798, 0.8282828282828283, 0.8333333333333334, 0.8617021276595744, 0.8415841584158416, 0.8514851485148515, 0.8446601941747572, 0.8613861386138614, 0.8777777777777778]\n",
            "Recap: F1 per fold: [0.8235294117647058, 0.7939698492462312, 0.8241206030150754, 0.8415841584158417, 0.8350515463917526, 0.845771144278607, 0.8557213930348259, 0.8571428571428571, 0.8656716417910448, 0.831578947368421]\n",
            "Average accuracy over 10 folds: 83.8%\n",
            "Average P over 10 folds: 84.06%\n",
            "Average R over 10 folds: 83.5%\n",
            "Average F1 over 10 folds: 83.74%\n"
          ]
        }
      ],
      "source": [
        "def extract_back_of_words_2nd(reviews):\n",
        "    stemmer = PorterStemmer()\n",
        "    words=set()\n",
        "    for i in reviews:\n",
        "        for line in i:\n",
        "            for word,tag in line:\n",
        "                words.add(word.lower()+\"_\"+tag)\n",
        "    back_of_words={}\n",
        "    for i,word in enumerate(words):\n",
        "        back_of_words[word]=i\n",
        "    return back_of_words\n",
        "\n",
        "def make_histogram_2nd(reviews,back_of_words):\n",
        "    stemmer = PorterStemmer()\n",
        "    histogram=np.zeros((len(reviews),len(back_of_words)))\n",
        "    for index,r in enumerate(reviews):\n",
        "        for line in r:\n",
        "            for word,tag in line:\n",
        "                if word.lower()+\"_\"+tag in back_of_words.keys():\n",
        "                    histogram[index][back_of_words[word.lower()+\"_\"+tag]]+=1\n",
        "    return histogram\n",
        "accuracy_per_fold,P_per_fold,R_per_fold,F1_per_fold = k_fold_cross_validation_svm(reviews,extract_back_of_words_2nd,make_histogram_2nd, k=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0dt_oQupUNe"
      },
      "source": [
        "**Answer to question Q3.2**\n",
        "\n",
        "We notice that the accuracy has increased after considering the word's position. That is expected, as before, a support vector could correspond to words that have multiple positions (i.e., park, \"where should I park my car?\", \"here is a park for the kids to play\") had one significance. Now, if a review mentions the park as a noun and verb, the SVM will think of it as two different objects, corresponding to two different support vectors and having more impact than it should have. Now that we have one weight for each POS tag for each word, the SVM can handle these cases. In all, this means that the SVM will have more inputs to work with, and as a result, it can find better support vectors that correspond to the better inputs to classify a review."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Su-3w87eMW0w"
      },
      "source": [
        "#### (Q3.3) Discard all closed-class words from your data (keep only nouns, verbs, adjectives, and adverbs), and report performance. Does this help? Use cross-validation to evaluate the classifier and compare the results with (Q3.2). Are closed-class words detrimental to the classifier? Explain why this may be the case. (1pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "CCUPlPozCYUX",
        "outputId": "c3837f84-2e30-43e8-8be9-119d354e9fdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting k-fold cross validation ......\n",
            "-------------------------------------------------------\n",
            "SVM classification accuracy: 82.5% in fold 0\n",
            "SVM classification P: 82.18% in fold 0\n",
            "SVM classification R: 83.0% in fold 0\n",
            "SVM classification F1: 82.59% in fold 0\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 83.5% in fold 1\n",
            "SVM classification P: 83.17% in fold 1\n",
            "SVM classification R: 84.0% in fold 1\n",
            "SVM classification F1: 83.58% in fold 1\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 83.5% in fold 2\n",
            "SVM classification P: 86.02% in fold 2\n",
            "SVM classification R: 80.0% in fold 2\n",
            "SVM classification F1: 82.9% in fold 2\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "SVM classification accuracy: 86.0% in fold 3\n",
            "SVM classification P: 85.29% in fold 3\n",
            "SVM classification R: 87.0% in fold 3\n",
            "SVM classification F1: 86.14% in fold 3\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "SVM classification accuracy: 84.5% in fold 4\n",
            "SVM classification P: 87.1% in fold 4\n",
            "SVM classification R: 81.0% in fold 4\n",
            "SVM classification F1: 83.94% in fold 4\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 83.5% in fold 5\n",
            "SVM classification P: 83.17% in fold 5\n",
            "SVM classification R: 84.0% in fold 5\n",
            "SVM classification F1: 83.58% in fold 5\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "SVM classification accuracy: 88.5% in fold 6\n",
            "SVM classification P: 91.4% in fold 6\n",
            "SVM classification R: 85.0% in fold 6\n",
            "SVM classification F1: 88.08% in fold 6\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "SVM classification accuracy: 86.0% in fold 7\n",
            "SVM classification P: 84.62% in fold 7\n",
            "SVM classification R: 88.0% in fold 7\n",
            "SVM classification F1: 86.27% in fold 7\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM classification accuracy: 87.5% in fold 8\n",
            "SVM classification P: 87.13% in fold 8\n",
            "SVM classification R: 88.0% in fold 8\n",
            "SVM classification F1: 87.56% in fold 8\n",
            "-------------------------------------------------------\n",
            "-------------------------------------------------------\n",
            "SVM classification accuracy: 83.5% in fold 9\n",
            "SVM classification P: 86.02% in fold 9\n",
            "SVM classification R: 80.0% in fold 9\n",
            "SVM classification F1: 82.9% in fold 9\n",
            "-------------------------------------------------------\n",
            "Recap: Accuracy per fold: [0.825, 0.835, 0.835, 0.86, 0.845, 0.835, 0.885, 0.86, 0.875, 0.835]\n",
            "Recap: P per fold: [0.83, 0.84, 0.8, 0.87, 0.81, 0.84, 0.85, 0.88, 0.88, 0.8]\n",
            "Recap: R per fold: [0.8217821782178217, 0.8316831683168316, 0.8602150537634409, 0.8529411764705882, 0.8709677419354839, 0.8316831683168316, 0.9139784946236559, 0.8461538461538461, 0.8712871287128713, 0.8602150537634409]\n",
            "Recap: F1 per fold: [0.8258706467661692, 0.835820895522388, 0.8290155440414508, 0.8613861386138614, 0.8393782383419689, 0.835820895522388, 0.8808290155440415, 0.8627450980392156, 0.8756218905472637, 0.8290155440414508]\n",
            "Average accuracy over 10 folds: 84.9%\n",
            "Average P over 10 folds: 85.61%\n",
            "Average R over 10 folds: 84.0%\n",
            "Average F1 over 10 folds: 84.76%\n"
          ]
        }
      ],
      "source": [
        "def extract_back_of_words_3rd(reviews):\n",
        "    stemmer = PorterStemmer()\n",
        "    words=set()\n",
        "    for i in reviews:\n",
        "        for line in i:\n",
        "            for word,tag in line:\n",
        "                if tag.startswith(\"JJ\") or tag.startswith(\"RB\") or tag.startswith(\"NN\") or tag.startswith(\"VB\"):\n",
        "                    words.add(word.lower()+\"_\"+tag)\n",
        "    back_of_words={}\n",
        "    for i,word in enumerate(words):\n",
        "        back_of_words[word]=i\n",
        "    return back_of_words\n",
        "\n",
        "def make_histogram_3rd(reviews,back_of_words):\n",
        "    stemmer = PorterStemmer()\n",
        "    histogram=np.zeros((len(reviews),len(back_of_words)))\n",
        "    for index,r in enumerate(reviews):\n",
        "        for line in r:\n",
        "            for word,tag in line:\n",
        "                if word.lower()+\"_\"+tag in back_of_words.keys():\n",
        "                    histogram[index][back_of_words[word.lower()+\"_\"+tag]]+=1\n",
        "    return histogram\n",
        "\n",
        "accuracy_per_fold,P_per_fold,R_per_fold,F1_per_fold = k_fold_cross_validation_svm(reviews,extract_back_of_words_3rd,make_histogram_3rd, k=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaxCVrs8pWSp"
      },
      "source": [
        "**Answer to question Q3.3**\n",
        "\n",
        "We once again notice an improvement from the second method. The outcome is expected as multiple closed-class words (like \"to,\" \"and,\" etc.) do not give any value to classify a review as positive or negative. So, the SVM in q3.2 considers them, which affects it negatively, as it does not matter how many \"to\" words we have. The SVM in q3.3 does not get affected by them as it discards them, thus a better result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfwqOciAl2No"
      },
      "source": [
        "# (4) Discussion (max. 500 words). (5pts)\n",
        "\n",
        "> Based on your experiments, what are the effective features and techniques in sentiment analysis? What information do different features encode?\n",
        "Why is this important? What are the limitations of these features and techniques?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYuse5WLmekZ"
      },
      "source": [
        "*Write your answer here in up to 500 words (-0.25pt for >50 extra words, -0.5 points for >100 extra words, ...)*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwaKwfWQhRk_"
      },
      "source": [
        "# Submission\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "aOUeaET5ijk-"
      },
      "outputs": [],
      "source": [
        "# Write your names and student numbers here:\n",
        "# Student 1 #12345\n",
        "# Student 2 #12345"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A9K-H6Tii3X"
      },
      "source": [
        "**That's it!**\n",
        "\n",
        "- Check if you answered all questions fully and correctly.\n",
        "- Download your completed notebook using `File -> Download .ipynb`\n",
        "- Check if your answers are all included in the file you submit.\n",
        "- Submit your .ipynb file via *Canvas*. One submission per group."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_27I7Qkm3pm"
      },
      "source": [
        "1. The lexicon-based approach predicts the sentiment of a review by parsing all tokens in a review. It computes a weighted binary score based on the priorpolarity and the importance of the priorpolarity of the words given by the lexicon. Then, the decision is made based on whether the score is higher or lower than a predefined threshold. The original assumption is that the review has approximately eight more positive than negative words (bias in the dataset). Having a fixed threshold as a bias during test time to classify a review, the method's accuracy can suffer depending on the review size (see Answer in **Q1.4**). The latter problem can be resolved by adjusting the threshold to each review size (document length).\n",
        "\n",
        "2. The Naive Bayes classifier essentially behaves as a model that does not account for neighborhood word correlations and is invariant to word occurrence in the text. In greater detail, we have made the following two assumptions. The bag of word model assumption (position does not matter) and the conditional independence (feature probabilities $P(x_{i}|c_{j})$ are independent given the class $c_{j}$). Overall, NB is a good baseline classifier for sentiment analysis tasks and behaves almost like a language model (explain more later). During our experiments, the following points were discovered:\n",
        " 1. Since Laplace smoothing tries to solve the problem of not having seen\n",
        "training documents with the words we are testing, it is redundant if we have already removed the unseen word in **Q2.1**. The latter observation is aligned with our experiments in **Q2.2 \\& Q.2.4**. As mentioned above, the NB classifier with Laplace smoothing achieves $82.5\\%$ accuracy (held-out set) without eliminating the unknown words. Compared to the approach where we eliminated the unknown words and applied Laplace smoothing, the classifier acquires $83.5\\%$ accuracy, the same as eliminating the unknown words but not applying any smoothing.\n",
        " 2. **TO DO ADD HERE**\n",
        " **Make comments about stemming and ngrams with NB**.\n",
        "\n",
        "3. The SVM classification is a method that first finds the frequencies of each word as unigrams without stemming and converts them as a vector for the review. Later, we insert them into an SVM classifier to train it and predict the labels of a test set. We see that with this basic technique, we have an accuracy of $83.25\\%$, similar to the Naive Bayes approach. A second approach is to consider the word's position, which helps the SVM better understand the meaning of each word and not confuse one word with another, thus having a better outcome than before. Lastly, we keep only the part of words that have meaning and discard closed-form words that may badly influence our classifier, which proves to be the best technique out of all, with an accuracy of $84.9\\%$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vN11e_rCm3pm"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}